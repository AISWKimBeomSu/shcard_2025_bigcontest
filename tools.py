"""
AI ë¹„ë°€ìƒë‹´ì‚¬ ë¶„ì„ ë„êµ¬ ëª¨ìŒ
3ê°œì˜ ë…ë¦½ì ì¸ ë¶„ì„ ëª¨ë¸ì„ LangChain Toolë¡œ ë¦¬íŒ©í† ë§
"""

import pandas as pd
import numpy as np
import requests
import json
from typing import Dict, Any, List, Tuple
from langchain_core.tools import tool

# =============================================================================
# ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =============================================================================

def get_score_from_raw(raw_value):
    """ì›ì‹œ ê°’ì„ ì ìˆ˜ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    if pd.isna(raw_value):
        return np.nan
    raw_str = str(raw_value)
    score_map = {"10%ì´í•˜": 6, "10-25%": 5, "25-50%": 4, "50-75%": 3, "75-90%": 2, "90%ì´ˆê³¼": 1}
    for key, score in score_map.items():
        if key in raw_str:
            return score
    return np.nan

def translate_metric(metric_type, raw_value):
    """ì§€í‘œë¥¼ ì‚¬ëŒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if pd.isna(raw_value):
        return "ì •ë³´ ì—†ìŒ"
    translation_map = {
        "tenure": {"10%ì´í•˜": "ìƒìœ„ 10% ì´ë‚´ (ê°€ì¥ ì˜¤ë˜ ìš´ì˜)", "10-25%": "ìƒìœ„ 10-25%", "25-50%": "ì¤‘ìƒìœ„ 25-50%", "50-75%": "ì¤‘í•˜ìœ„ 50-75%", "75-90%": "í•˜ìœ„ 10-25%", "90%ì´ˆê³¼": "í•˜ìœ„ 10% ì´ë‚´ (ê°€ì¥ ìµœê·¼ ì‹œì‘)"},
        "level": {"10%ì´í•˜": "ìƒìœ„ 10% ì´ë‚´ (ê°€ì¥ ë†’ìŒ)", "10-25%": "ìƒìœ„ 10-25%", "25-50%": "ì¤‘ìƒìœ„ 25-50%", "50-75%": "ì¤‘í•˜ìœ„ 50-75%", "75-90%": "í•˜ìœ„ 10-25%", "90%ì´ˆê³¼": "í•˜ìœ„ 10% ì´ë‚´ (ê°€ì¥ ë‚®ìŒ)"}
    }
    explanation_map = translation_map.get(metric_type, {})
    for key, explanation in explanation_map.items():
        if key in str(raw_value):
            return f"{raw_value} ({explanation})"
    return str(raw_value)

def score_to_level_text(score):
    """ì ìˆ˜ë¥¼ ë ˆë²¨ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if pd.isna(score):
        return "ì •ë³´ ì—†ìŒ"
    if score >= 5.5:
        return "ìµœìƒìœ„ 10% ìˆ˜ì¤€"
    if score >= 4.5:
        return "ìƒìœ„ 10-25% ìˆ˜ì¤€"
    if score >= 3.5:
        return "ì¤‘ìƒìœ„ 25-50% ìˆ˜ì¤€"
    if score >= 2.5:
        return "ì¤‘í•˜ìœ„ 50-75% ìˆ˜ì¤€"
    if score >= 1.5:
        return "í•˜ìœ„ 10-25% ìˆ˜ì¤€"
    return "í•˜ìœ„ 10% ìˆ˜ì¤€"

# =============================================================================
# ëª¨ë¸ 1: ì¹´í˜ ì—…ì¢… ì£¼ìš” ê³ ê° ë¶„ì„ ë° ë§ˆì¼€íŒ… ì±„ë„/í™ë³´ì•ˆ ì¶”ì²œ
# =============================================================================

# AIì˜ ì§€ì‹ ë² ì´ìŠ¤ - í˜ë¥´ì†Œë‚˜ ë§µ
PERSONA_MAP = {
    'M12_FME_1020_RAT': {'name': 'ë””ì§€í„¸ íë ˆì´í„°', 'desc': '10-20ëŒ€ ì—¬ì„±', 'features': 'SNS ê³µìœ ë¥¼ í†µí•œ ì •ì²´ì„± í˜•ì„±, ë””í†  ì†Œë¹„, ê°€ì„±ë¹„ì™€ ê°€ì‹¬ë¹„ì˜ ì „ëµì  í˜¼í•©'},
    'M12_MAL_1020_RAT': {'name': 'íŠ¸ë Œë“œ ê²€ì¦ê°€', 'desc': '10-20ëŒ€ ë‚¨ì„±', 'features': 'ì˜¨ë¼ì¸ íŠ¸ë Œë“œì˜ ì˜¤í”„ë¼ì¸ ê²½í—˜ ë° ê²€ì¦, ê°€ì„±ë¹„ ì¤‘ì‹œ, ë² ì´ìŠ¤ìº í”„ë¡œì„œì˜ ê³µê°„ í™œìš©'},
    'M12_FME_30_RAT': {'name': 'ì „ëµì  ìµœì í™” ì „ë¬¸ê°€', 'desc': '30ëŒ€ ì—¬ì„±', 'features': 'ì‹œê°„/ë¹„ìš©/ì—ë„ˆì§€ì˜ ìµœì í™”, ê°€ì¹˜ ê²½í—˜ ê·¹ëŒ€í™”, ë¶„ì´ˆì‚¬íšŒ'},
    'M12_MAL_30_RAT': {'name': 'íš¨ìœ¨ ì¶”êµ¬ í”„ë¡œí˜ì…”ë„', 'desc': '30ëŒ€ ë‚¨ì„±', 'features': 'ì—…ë¬´ì™€ ì¼ìƒ ì† ëª¨ë“  ì ‘ì ì—ì„œ ì‹œê°„ê³¼ ë…¸ë ¥ ì ˆì•½, ê¸°ëŠ¥ì  ì†Œë¹„'},
    'M12_FME_40_RAT': {'name': 'ê°€ì¡± ì›°ë¹™ ì„¤ê³„ì', 'desc': '40ëŒ€ ì—¬ì„±', 'features': 'ê°€ì¡±ì˜ ê±´ê°•ê³¼ ê²½í—˜ì— ëŒ€í•œ í”„ë¦¬ë¯¸ì—„ ê°€ì¹˜ íˆ¬ì, ì»¤ë®¤ë‹ˆí‹° ì •ë³´ êµë¥˜'},
    'M12_MAL_40_RAT': {'name': 'ì•ˆì • ì¶”êµ¬ ë¦¬ë”', 'desc': '40ëŒ€ ë‚¨ì„±', 'features': 'ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë¸Œëœë“œë¥¼ í†µí•œ ìœ„í—˜ ìµœì†Œí™”, ê²€ì¦ëœ í’ˆì§ˆ ì„ í˜¸'},
    'M12_FME_50_RAT': {'name': 'ì»¤ë®¤ë‹ˆí‹° ì•µì»¤', 'desc': '50ëŒ€ ì—¬ì„±', 'features': 'ì‚¬íšŒì  ê´€ê³„ë§ì˜ ì¤‘ì‹¬ìœ¼ë¡œì„œ ì†Œí†µê³¼ êµë¥˜ ì£¼ë„, í¸ì•ˆí•¨ê³¼ ê´€ê³„ ì¤‘ì‹œ'},
    'M12_MAL_50_RAT': {'name': 'ë¡œì»¬ í—ˆë¸Œ', 'desc': '50ëŒ€ ë‚¨ì„±', 'features': 'ë‹¨ê³¨ ë¬¸í™”ë¥¼ í†µí•´ ì§€ì—­ ì»¤ë®¤ë‹ˆí‹°ì˜ êµ¬ì‹¬ì  ì—­í• , ìµìˆ™í•¨ ì„ í˜¸'},
    'M12_FME_60_RAT': {'name': 'ì›°ë‹ˆìŠ¤ ë¼ì´í”„ ì¶”êµ¬ì', 'desc': '60ëŒ€ ì´ìƒ ì—¬ì„±', 'features': 'ì‹ ì²´ì /ì •ì„œì  ì›°ë¹™ì„ ìœ„í•œ ì ê·¹ì ì¸ ì†Œë¹„ì™€ í™œë™'},
    'M12_MAL_60_RAT': {'name': 'ê²½í—˜ ê°€ì¹˜ íˆ¬ìì', 'desc': '60ëŒ€ ì´ìƒ ë‚¨ì„±', 'features': 'ì¶•ì ëœ ìì‚°ì„ í†µí•´ ê´€ê³„ì™€ ì˜ë¯¸ ìˆëŠ” ê²½í—˜ì— íˆ¬ì'}
}

@tool
def cafe_marketing_tool(store_id: str, df_cafe_customers: pd.DataFrame, df_all_join: pd.DataFrame, df_prompt_dna: pd.DataFrame) -> str:
    """
    ì¹´í˜ ì—…ì¢… ê°€ë§¹ì ì˜ ì£¼ìš” ë°©ë¬¸ ê³ ê° íŠ¹ì„±ì„ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ê³ , 
    ê°€ì¥ íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ… ì±„ë„ê³¼ êµ¬ì²´ì ì¸ í™ë³´ ë¬¸êµ¬ë¥¼ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ ë„êµ¬.
    'ì¹´í˜', 'ê³ ê° ë¶„ì„', 'í™ë³´' ê´€ë ¨ ì§ˆë¬¸ì— ì‚¬ìš©ëœë‹¤.
    
    Args:
        store_id: ë¶„ì„í•  ê°€ë§¹ì  ID
        df_cafe_customers: ì¹´í˜ ê°€ë§¹ì ë³„ ì£¼ìš”ê³ ê° ë°ì´í„°
        df_all_join: ì „ì²´ JOIN ë°ì´í„°
        df_prompt_dna: AIìƒë‹´ì‚¬ í•µì‹¬ì „ëµ í”„ë¡¬í”„íŠ¸ ë°ì´í„°
    
    Returns:
        ë¶„ì„ ê²°ê³¼ ë° ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆ ë¦¬í¬íŠ¸
    """
    try:
        # 1ë‹¨ê³„: ë°ì´í„° ë¶„ì„ ì—”ì§„
        customer_data = df_cafe_customers[df_cafe_customers['ENCODED_MCT'] == store_id]
        if customer_data.empty:
            return f"ë¶„ì„ ì‹¤íŒ¨: '{store_id}' ê°€ë§¹ì ì˜ ì£¼ìš” ê³ ê° ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì£¼ìš” ê³ ê°ì¸µ ë¶„ì„ (ê²©ì°¨ ë°©ì‹ ì ìš©)
        persona_columns = list(PERSONA_MAP.keys())
        store_persona_data = customer_data[persona_columns].iloc[0].astype(float)
        
        max_value = store_persona_data.max()
        threshold = max_value - 5.0
        
        top_segments = store_persona_data[store_persona_data >= threshold]
        
        # ê²°ê³¼ê°€ 2ê°œë¥¼ ì´ˆê³¼í•  ê²½ìš°, ê°€ì¥ ë†’ì€ ìƒìœ„ 2ê°œë§Œ ì„ íƒ
        if len(top_segments) > 2:
            top_segments = top_segments.sort_values(ascending=False).head(2)
            
        if top_segments.empty:
            return f"ë¶„ì„ ì‹¤íŒ¨: '{store_id}' ê°€ë§¹ì ì˜ ìœ íš¨í•œ ì£¼ìš” ê³ ê°ì¸µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        main_personas_info = [PERSONA_MAP[seg] for seg in top_segments.index]
        main_personas_str = ", ".join([f"{p['name']}({p['desc']})" for p in main_personas_info])
        
        # í•µì‹¬ ì„±ê³µ ì „ëµ ë¶„ì„
        store_data = df_all_join[df_all_join['ENCODED_MCT'] == store_id]
        if store_data.empty:
            return f"ë¶„ì„ ì‹¤íŒ¨: '{store_id}' ê°€ë§¹ì ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        latest_data = store_data.sort_values(by='TA_YM', ascending=False).iloc[0]
        store_commercial_area = latest_data['HPSN_MCT_BZN_CD_NM']
        
        if pd.isna(store_commercial_area):
            store_commercial_area = 'ë¹„ìƒê¶Œ'
        
        dna_row = df_prompt_dna[(df_prompt_dna['ìƒê¶Œ'] == store_commercial_area) & (df_prompt_dna['ì—…ì¢…'] == 'ì¹´í˜')]
        if dna_row.empty:
            return f"ë¶„ì„ ì‹¤íŒ¨: '{store_commercial_area}' ìƒê¶Œì˜ 'ì¹´í˜' ì—…ì¢… ì„±ê³µ DNAë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        core_strategy = dna_row['í•µì‹¬ê²½ì˜ì „ëµ'].iloc[0]

        # 2ë‹¨ê³„: LLM í˜¸ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt_for_gemini = f"""
ë„ˆëŠ” ì†Œìƒê³µì¸ ì¹´í˜ ì‚¬ì¥ë‹˜ì„ ìœ„í•œ ì „ë¬¸ ë§ˆì¼€íŒ… ì „ëµê°€ 'AI ë¹„ë°€ìƒë‹´ì‚¬'ì•¼.

### ë°ì´í„° ë¶„ì„ ê²°ê³¼
- **[WHO] ìš°ë¦¬ ê°€ê²Œ í•µì‹¬ ê³ ê°:** {main_personas_str}
- **[WHAT] ê°€ê²Œì˜ ì„±ê³µ ì „ëµ:** '{core_strategy}'

### ê³¼ì—… ì§€ì‹œ
ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ì¥ë‹˜ì´ **ì¦‰ì‹œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” 'ë§ˆì¼€íŒ… ì±„ë„'ê³¼ 'í™ë³´ ë°©ì•ˆ'**ì„ ì¶”ì²œí•´ì¤˜.

### ê²°ê³¼ë¬¼ í˜•ì‹ ë° ì‘ì„± ê°€ì´ë“œë¼ì¸
1.  **ë‹µë³€ í˜•ì‹:** ê²°ê³¼ë¬¼ì€ **'ğŸ“ˆ ì¶”ì²œ ë§ˆì¼€íŒ… ì±„ë„'**ê³¼ **'ğŸ’¡ ì¶”ì²œ í™ë³´ ë°©ì•ˆ'** ë‘ ë¶€ë¶„ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ë‚˜ëˆ„ì–´ì¤˜.
2.  **ì±„ë„ ì¶”ì²œ:** ê° ì±„ë„ì„ ì¶”ì²œí•  ë•Œ, **ì™œ ì´ ê³ ê°ë“¤ì—ê²Œ ì´ ì±„ë„ì´ íš¨ê³¼ì ì¸ì§€** í•µì‹¬ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.
3.  **í™ë³´ ë°©ì•ˆ:**
    - **ìµœì†Œ 3ê°€ì§€ ì´ìƒ**ì˜ êµ¬ì²´ì ì¸ ì•¡ì…˜ í”Œëœì„ ì œì‹œí•´ì¤˜.
    - ê° ë°©ì•ˆë§ˆë‹¤ **'ë¬´ì—‡ì„(What)'**ê³¼ **'ì–´ë–»ê²Œ(How)'** í•  ìˆ˜ ìˆëŠ”ì§€ ì‚¬ì¥ë‹˜ì´ ë°”ë¡œ ì´í•´í•˜ë„ë¡ ì‹¤ì œ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì¤˜.
    - ë§Œì•½ í•µì‹¬ ê³ ê°ì´ ì—¬ëŸ¬ ê·¸ë£¹ì´ë¼ë©´, ê·¸ë“¤ì˜ **ê³µí†µì ì„ ê³µëµí•˜ê±°ë‚˜ ì‹œë„ˆì§€ë¥¼ ë‚¼ ìˆ˜ ìˆëŠ”** í†µí•©ì ì¸ ì•„ì´ë””ì–´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì œì•ˆí•´ì¤˜.
4.  **ì „ì²´ í†¤ì•¤ë§¤ë„ˆ:** ì‚¬ì¥ë‹˜ì´ ì‰½ê²Œ ì´í•´í•˜ê³  ë°”ë¡œ ìš©ê¸°ë¥¼ ì–»ì–´ ì‹¤í–‰í•´ ë³¼ ìˆ˜ ìˆë„ë¡, ì¹œê·¼í•˜ê³  ëª…í™•í•˜ë©° ì„¤ë“ë ¥ ìˆëŠ” í†¤ì•¤ë§¤ë„ˆë¥¼ ì‚¬ìš©í•´ì¤˜.
"""

        # 3ë‹¨ê³„: ìµœì¢… ë¦¬í¬íŠ¸ ì¡°í•©
        final_report = f"""
======================================================================
      ğŸ¤– AI ë¹„ë°€ìƒë‹´ì‚¬ - '{store_id}' ê°€ë§¹ì  ë§ì¶¤ ì „ëµ ë¦¬í¬íŠ¸
======================================================================

### ğŸ“Š ë°ì´í„° ë¶„ì„ ìš”ì•½

* **[WHO] ìš°ë¦¬ ê°€ê²Œ í•µì‹¬ ê³ ê°:** {main_personas_str}
* **[WHAT] ì‹œì¥ì—ì„œ ì‚´ì•„ë‚¨ì„ ì—´ì‡ :** {core_strategy}

----------------------------------------------------------------------

### ğŸš€ AIê°€ ì œì•ˆí•˜ëŠ” ë§ì¶¤ ë§ˆì¼€íŒ… ì „ëµ

{prompt_for_gemini}

**ğŸ’¡ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì „ëµ:**

1. **íƒ€ê²Ÿ ê³ ê° ë§ì¶¤ ì±„ë„ í™œìš©**
   - {main_personas_str} ê³ ê°ì¸µì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì±„ë„ ì„ íƒ
   - ê° ê³ ê°ì¸µì˜ ì„ í˜¸í•˜ëŠ” ì†Œí†µ ë°©ì‹ê³¼ í”Œë«í¼ í™œìš©

2. **í•µì‹¬ ì „ëµ ê¸°ë°˜ ë©”ì‹œì§€ ê°œë°œ**
   - '{core_strategy}' ì „ëµì„ ë°˜ì˜í•œ ë§ˆì¼€íŒ… ë©”ì‹œì§€ êµ¬ì„±
   - ê³ ê°ì˜ ë‹ˆì¦ˆì™€ ê°€ê²Œì˜ ê°•ì ì„ ì—°ê²°í•˜ëŠ” ìŠ¤í† ë¦¬í…”ë§

3. **ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš**
   - 1ë‹¨ê³„: ê³ ê°ì¸µë³„ ë§ì¶¤ ì±„ë„ ì„¤ì •
   - 2ë‹¨ê³„: í•µì‹¬ ë©”ì‹œì§€ ê°œë°œ ë° í…ŒìŠ¤íŠ¸
   - 3ë‹¨ê³„: ì„±ê³¼ ì¸¡ì • ë° ìµœì í™”

"""
        return final_report

    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return f"""ğŸš¨ ì¹´í˜ ë§ˆì¼€íŒ… ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ìƒì„¸ ì •ë³´:**
- ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}
- ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}
- ê°€ë§¹ì  ID: {store_id}

**í•´ê²° ë°©ë²•:**
1. ê°€ë§¹ì  IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
2. ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ê°€ë§¹ì  ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
3. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”

**ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:**
{error_details}"""

# =============================================================================
# ëª¨ë¸ 2: ì¬ë°©ë¬¸ìœ¨ 30% ì´í•˜ ê°€ë§¹ì  ì›ì¸ ì§„ë‹¨ ë° A/B ì „ëµ ì œì•ˆ
# =============================================================================

@tool
def revisit_rate_analysis_tool(store_id: str, df_all_join: pd.DataFrame, df_prompt_dna: pd.DataFrame) -> str:
    """
    ì¬ë°©ë¬¸ìœ¨ì´ 30% ì´í•˜ë¡œ ë‚®ì€ ê°€ë§¹ì ì˜ ê·¼ë³¸ì ì¸ ì›ì¸ì„ 3ê°€ì§€ í•µì‹¬ ë™ì¸(ê°€ê²©, ê³ ê°ì¸µ, ì±„ë„)ìœ¼ë¡œ 
    ê²½ìŸ ê·¸ë£¹ê³¼ ë¹„êµ ë¶„ì„í•˜ê³ , ì¬ë°©ë¬¸ìœ¨ì„ ë†’ì´ê¸° ìœ„í•œ A/B ì „ëµì„ ì œì•ˆí•˜ëŠ” ë„êµ¬.
    'ì¬ë°©ë¬¸', 'ë‹¨ê³¨' ë¬¸ì œì— íŠ¹í™”ë˜ì–´ ìˆë‹¤.
    
    Args:
        store_id: ë¶„ì„í•  ê°€ë§¹ì  ID
        df_all_join: ì „ì²´ JOIN ë°ì´í„°
        df_prompt_dna: AIìƒë‹´ì‚¬ í•µì‹¬ì „ëµ í”„ë¡¬í”„íŠ¸ ë°ì´í„°
    
    Returns:
        ì¬ë°©ë¬¸ìœ¨ ë¶„ì„ ë° ê°œì„  ì „ëµ ë¦¬í¬íŠ¸
    """
    try:
        target_store_all_months = df_all_join[df_all_join['ENCODED_MCT'] == store_id]
        if target_store_all_months.empty:
            return f"ğŸš¨ ë¶„ì„ ë¶ˆê°€: ë°ì´í„°ì…‹ì—ì„œ '{store_id}' ê°€ë§¹ì  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        target_store = target_store_all_months.sort_values(by='TA_YM', ascending=False).iloc[0]

        # ì¬ë°©ë¬¸ìœ¨ ê³„ì‚° (ì›”ë³„ í‰ê· )
        target_revisit_rate_series = target_store_all_months['MCT_UE_CLN_REU_RAT'].dropna()
        target_revisit_rate = 0.0 if target_revisit_rate_series.empty else target_revisit_rate_series.mean()

        if target_revisit_rate >= 30:
            latest_month = target_store.get('TA_YM', 'ìµœì‹ ')
            return f"âœ… ë¶„ì„ ê²°ê³¼: ì›” í‰ê·  ì¬ë°©ë¬¸ìœ¨ì´ {target_revisit_rate:.1f}%ë¡œ ì–‘í˜¸í•©ë‹ˆë‹¤. (ìµœì‹ ì›”: {latest_month})"

        industry, commercial_area = target_store['ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜'], target_store['HPSN_MCT_BZN_CD_NM']
        area_name = commercial_area if pd.notna(commercial_area) else "ë¹„ìƒê¶Œ"
        
        # ê²½ìŸ ê·¸ë£¹ ì„¤ì •
        peer_group_filter = (df_all_join['ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜'] == industry) & (df_all_join['ENCODED_MCT'] != store_id)
        if pd.isna(commercial_area):
            peer_group = df_all_join[peer_group_filter & (df_all_join['HPSN_MCT_BZN_CD_NM'].isna())]
        else:
            peer_group = df_all_join[peer_group_filter & (df_all_join['HPSN_MCT_BZN_CD_NM'] == commercial_area)]

        if len(peer_group) < 3:
            return f"ğŸŸ¡ ë¶„ì„ ë³´ë¥˜: ë¹„êµ ë¶„ì„ì„ ìœ„í•œ ê²½ìŸ ê·¸ë£¹ì´ ë¶€ì¡±í•©ë‹ˆë‹¤."
            
        revisit_threshold = peer_group['MCT_UE_CLN_REU_RAT'].quantile(0.5)
        successful_peers = peer_group[peer_group['MCT_UE_CLN_REU_RAT'] >= revisit_threshold]
        if successful_peers.empty:
            return f"ğŸŸ¡ ë¶„ì„ ë³´ë¥˜: ì„±ê³µ ê·¸ë£¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # 3ëŒ€ ì§€í‘œ ê³„ì‚°
        def get_series_mean(series):
            series_cleaned = series.dropna()
            return 0.0 if series_cleaned.empty else series_cleaned.mean()

        def get_group_mean(df, group_col, value_col):
            if df.empty or value_col not in df.columns:
                return 0.0
            group_means = df.groupby(group_col)[value_col].mean()
            final_mean = group_means.mean()
            return 0.0 if pd.isna(final_mean) else final_mean

        # ë‚´ ê°€ê²Œì˜ ì „ì²´ ê¸°ê°„ í‰ê·  ê³„ì‚°
        target_price_score_avg = get_series_mean(target_store_all_months['RC_M1_AV_NP_AT_SCORE'])
        target_resident_ratio_avg = get_series_mean(target_store_all_months['RC_M1_SHC_RSD_UE_CLN_RAT'])
        target_delivery_ratio_avg = get_series_mean(target_store_all_months['DLV_SAA_RAT'])

        # ì„±ê³µ ê·¸ë£¹ì˜ ê°€ê²Œë³„ í‰ê·  ê³„ì‚° í›„ -> ì „ì²´ í‰ê· 
        peer_price_score_avg = get_group_mean(successful_peers, 'ENCODED_MCT', 'RC_M1_AV_NP_AT_SCORE')
        peer_resident_ratio_avg = get_group_mean(successful_peers, 'ENCODED_MCT', 'RC_M1_SHC_RSD_UE_CLN_RAT')
        peer_delivery_avg = get_group_mean(successful_peers, 'ENCODED_MCT', 'DLV_SAA_RAT')
        
        # ë°°ë‹¬ ë¯¸ìš´ì˜ ê°€ê²Œ ì²˜ë¦¬ ë¡œì§
        is_delivery_not_operated = (target_delivery_ratio_avg == 0.0)
        
        delivery_target_for_analysis = target_delivery_ratio_avg
        delivery_peer_for_analysis = peer_delivery_avg

        if is_delivery_not_operated:
            delivery_peer_for_analysis = 0.0
            delivery_target_for_analysis = 0.0

        analysis_results = {
            'price_competitiveness': {'target': target_price_score_avg, 'peer_avg': peer_price_score_avg},
            'audience_alignment': {'target': target_resident_ratio_avg, 'peer_avg': peer_resident_ratio_avg},
            'channel_expansion': {'target': delivery_target_for_analysis, 'peer_avg': delivery_peer_for_analysis}
        }
        
        for key in analysis_results:
            analysis_results[key]['gap'] = analysis_results[key].get('target', np.nan) - analysis_results[key].get('peer_avg', np.nan)
        
        # í˜ë¥´ì†Œë‚˜ ì§„ë‹¨
        gaps = {k: v['gap'] for k, v in analysis_results.items() if 'gap' in v and pd.notna(v['gap'])}
        if not gaps:
            persona = "ë¶„ì„ ë¶ˆê°€"
        else:
            op_tenure_score = target_store.get('MCT_OPE_MS_CN_SCORE', 6)
            new_ratio = target_store.get('MCT_UE_CLN_NEW_RAT', 0)
            
            if op_tenure_score <= 2 and new_ratio > 60:
                persona = "ì²«ì¸ìƒë§Œ ì¢‹ì€ ì‹ ê·œ ë§¤ì¥"
            elif gaps.get('price_competitiveness', 0) < -1:
                persona = "ì¬ë°©ë¬¸í•˜ê¸°ì—” ë¶€ë‹´ìŠ¤ëŸ¬ìš´ ê°€ê²©"
            elif gaps.get('audience_alignment', 0) < -15:
                persona = "ë™ë„¤ ì£¼ë¯¼ì„ ì‚¬ë¡œì¡ì§€ ëª»í•˜ëŠ” ë§¤ì¥"
            elif gaps.get('channel_expansion', 0) < -20:
                persona = "ë°°ë‹¬ ì±„ë„ ë¶€ì¬"
            else:
                persona = "ì´ì²´ì  ë§ˆì¼€íŒ… ë¶€ì¬"

        # ì „ëµ ë°ì´í„° ì¡°íšŒ
        strategy_row = df_prompt_dna[(df_prompt_dna['ì—…ì¢…'] == industry) & (df_prompt_dna['ìƒê¶Œ'] == area_name)]
        if not strategy_row.empty:
            key_factor = strategy_row.iloc[0]['í•µì‹¬ì„±ê³µë³€ìˆ˜(DNA)']
            key_strategy = strategy_row.iloc[0]['í•µì‹¬ê²½ì˜ì „ëµ']
        else:
            key_factor = "ë°ì´í„° ì—†ìŒ"
            key_strategy = "ì¼ë°˜ì ì¸ ê°œì„  ì „ëµ í•„ìš”"

        # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        final_report = f"""
======================================================================
      ğŸ©º AI ì¬ë°©ë¬¸ìœ¨ ì§„ë‹¨ - '{store_id}' ê°€ë§¹ì  ë¶„ì„ ë¦¬í¬íŠ¸
======================================================================

### ğŸ“Š í˜„ì¬ ìƒí™© ì§„ë‹¨

* **ì—…ì¢…/ìƒê¶Œ:** {industry} / {area_name}
* **í˜„ì¬ ì¬ë°©ë¬¸ìœ¨:** {target_revisit_rate:.1f}% (ì›” í‰ê· )
* **AI ì§„ë‹¨ í˜ë¥´ì†Œë‚˜:** {persona}

### ğŸ” 3ëŒ€ í•µì‹¬ ë™ì¸ ë¶„ì„

**â‘  ê°€ê²© ê²½ìŸë ¥ (ê°ë‹¨ê°€)**
- ë‚´ ê°€ê²Œ: {target_price_score_avg:.2f}ì 
- ì„±ê³µ ê·¸ë£¹ í‰ê· : {peer_price_score_avg:.2f}ì 
- ê²©ì°¨: {analysis_results['price_competitiveness']['gap']:.2f}ì 

**â‘¡ í•µì‹¬ ê³ ê°ì¸µ (ê±°ì£¼ì ë¹„ìœ¨)**
- ë‚´ ê°€ê²Œ: {target_resident_ratio_avg:.1f}%
- ì„±ê³µ ê·¸ë£¹ í‰ê· : {peer_resident_ratio_avg:.1f}%
- ê²©ì°¨: {analysis_results['audience_alignment']['gap']:.1f}%p

**â‘¢ ì±„ë„ í™•ì¥ì„± (ë°°ë‹¬ ë¹„ìœ¨)**
- ë‚´ ê°€ê²Œ: {target_delivery_ratio_avg:.1f}%
- ì„±ê³µ ê·¸ë£¹ í‰ê· : {peer_delivery_avg:.1f}%
- ê²©ì°¨: {analysis_results['channel_expansion']['gap']:.1f}%p

### ğŸš€ ê°œì„  ì „ëµ ì œì•ˆ

**í•µì‹¬ ì„±ê³µ ë³€ìˆ˜:** {key_factor}
**í•µì‹¬ ê²½ì˜ ì „ëµ:** {key_strategy}

**A/B ì „ëµ ì˜µì…˜:**

**ì „ëµ A (ê°•ì  ê°•í™”/ì°¨ë³„í™”):**
- í˜„ì¬ ì˜í•˜ê³  ìˆëŠ” ë¶€ë¶„ì„ ë”ìš± ê°•í™”
- ì‹œì¥ì˜ ê·œì¹™ì„ ë”°ë¥´ëŠ” ëŒ€ì‹  ìƒˆë¡œìš´ ê·œì¹™ì„ ë§Œë“œëŠ” ì „ëµ

**ì „ëµ B (ì•½ì  ë³´ì™„/ë™ê¸°í™”):**
- ì„±ê³µ ê·¸ë£¹ì˜ ì „ëµì„ ë²¤ì¹˜ë§ˆí‚¹
- ì•ˆì •ì ì¸ ì„±ê³µ ë°©ì •ì‹ì„ ë”°ë¥´ëŠ” ì „ëµ

### ğŸ’¡ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ í”Œëœ

1. **ë‹¨ê¸° ê¸´ê¸‰ ì²˜ë°© (1-2ì£¼)**
   - {persona} ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜

2. **ì¤‘ì¥ê¸° í•µì‹¬ ì „ëµ (1-3ê°œì›”)**
   - {key_strategy} ê¸°ë°˜ì˜ ì²´ê³„ì ì¸ ê°œì„  ê³„íš

3. **ì„±ê³¼ ì¸¡ì • ë° ìµœì í™”**
   - ì¬ë°©ë¬¸ìœ¨ ë³€í™” ëª¨ë‹ˆí„°ë§ ë° ì „ëµ ì¡°ì •

"""
        return final_report

    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return f"""ğŸš¨ ì¬ë°©ë¬¸ìœ¨ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ìƒì„¸ ì •ë³´:**
- ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}
- ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}
- ê°€ë§¹ì  ID: {store_id}

**í•´ê²° ë°©ë²•:**
1. ê°€ë§¹ì  IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
2. ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ê°€ë§¹ì  ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
3. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”

**ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:**
{error_details}"""

# =============================================================================
# ëª¨ë¸ 3: ìš”ì‹ì—…ì¢… ê°€ë§¹ì ì˜ ì „ë°©ìœ„ ê°•ì /ì•½ì  ë¶„ì„ ë° ì†”ë£¨ì…˜ ì œì•ˆ
# =============================================================================

def apply_emphasis(score):
    """ì ìˆ˜ë¥¼ 0-100 ë²”ìœ„ì—ì„œ ì–‘ ê·¹ë‹¨ìœ¼ë¡œ ìŠ¤íŠ¸ë ˆì¹­í•˜ì—¬ ì°¨ì´ë¥¼ ëª…í™•í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤."""
    x = (score - 50) / 50
    y = np.sign(x) * (abs(x) ** 0.7)
    return max(0, min(100, (y * 50) + 50))

def get_percentile_score(store_value, benchmark_series, higher_is_better=True):
    """ê²½ìŸ ê·¸ë£¹ ë‚´ ë°±ë¶„ìœ„ ìˆœìœ„ë¥¼ 0-100ì  ì²™ë„ì˜ 'ê±´ê°• ì ìˆ˜'ë¡œ ë³€í™˜í•˜ê³  ê°€ì¤‘ì¹˜ë¥¼ ì ìš©"""
    if pd.isna(store_value) or benchmark_series.empty:
        return 50
    combined = pd.concat([benchmark_series, pd.Series([store_value])])
    percentile = combined.rank(pct=True, na_option='bottom').iloc[-1]
    raw_score = percentile * 100 if higher_is_better else (1 - percentile) * 100
    return apply_emphasis(raw_score)

def parse_segment(segment_name):
    """ì„¸ê·¸ë¨¼íŠ¸ ì´ë¦„ì„ íŒŒì‹±í•˜ì—¬ ì„±ë³„ê³¼ ì—°ë ¹ ì •ë³´ ì¶”ì¶œ"""
    parts = segment_name.replace('M12_', '').replace('_RAT', '').split('_')
    return {'name': segment_name, 'gender': parts[0], 'age': parts[1]}

def get_age_tier(age_str):
    """ì—°ë ¹ëŒ€ë¥¼ ìˆ«ìë¡œ ë³€í™˜"""
    tiers = {'1020': 1, '30': 2, '40': 3, '50': 4, '60': 5}
    return tiers.get(age_str, 0)

def calculate_advanced_match_score(area_top2_names, store_top2_names):
    """'Top 2 ë¹„êµ ë° ìœ ì‚¬ë„ ë³´ë„ˆìŠ¤' ë¡œì§ìœ¼ë¡œ ì í•©ë„ ì ìˆ˜ ê³„ì‚°"""
    intersection_count = len(set(area_top2_names) & set(store_top2_names))
    
    base_score = 0
    if intersection_count == 2:
        base_score = 85
    elif intersection_count == 1:
        base_score = 45
    else:
        base_score = 5

    bonus_score = 0
    non_matching_area = [parse_segment(s) for s in set(area_top2_names) - set(store_top2_names)]
    non_matching_store = [parse_segment(s) for s in set(store_top2_names) - set(store_top2_names)]

    for s_seg in non_matching_store:
        for a_seg in non_matching_area:
            if s_seg['age'] == a_seg['age']:
                bonus_score = max(bonus_score, 10)
            if s_seg['gender'] == a_seg['gender'] and abs(get_age_tier(s_seg['age']) - get_age_tier(a_seg['age'])) == 1:
                bonus_score = max(bonus_score, 5)
    
    return max(0, min(100, base_score + bonus_score))

@tool # ì—¬ê¸° ìˆ˜ì •í•´ì•¼í•¨(ê°€ë§¹ì  ëª… í˜•ì‹ ì˜¤ë¥˜)
def search_merchant_tool(merchant_name: str, df_all_join: pd.DataFrame) -> str:
    """
    ê°€ë§¹ì  ì´ë¦„ì„ ì…ë ¥ë°›ì•„, í•´ë‹¹ ê°€ë§¹ì ì˜ ê¸°ë³¸ ì •ë³´(ì—…ì¢…, ì£¼ì†Œ, ê°œì„¤ì¼ ë“±)ë¥¼ 
    ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬.
    ì‚¬ìš©ìê°€ ê°€ê²Œì˜ ê¸°ë³¸ ì •ë³´ë§Œ ìš”ì²­í•  ë•Œ ì‚¬ìš©ëœë‹¤.
    
    Args:
        merchant_name: ê²€ìƒ‰í•  ê°€ë§¹ì ëª… (ë¶€ë¶„ ì¼ì¹˜ ì§€ì›)
        df_all_join: ì „ì²´ JOIN ë°ì´í„°
    
    Returns:
        ê°€ë§¹ì  ê²€ìƒ‰ ê²°ê³¼ ë¦¬í¬íŠ¸
    """
    try:
        # ê°€ë§¹ì ëª…ìœ¼ë¡œ ê²€ìƒ‰ (exact match)
        result = df_all_join[df_all_join['ê°€ë§¹ì ëª…'].astype(str).str.replace('*', '') == merchant_name.replace('*', '')]
        
        if len(result) == 0:
            return f"""
ğŸš¨ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ

'{merchant_name}'ì— í•´ë‹¹í•˜ëŠ” ê°€ë§¹ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ğŸ’¡ ê²€ìƒ‰ íŒ:
- ì •í™•í•œ ê°€ë§¹ì ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”
- '*' ê¸°í˜¸ëŠ” ìë™ìœ¼ë¡œ ì œê±°ë©ë‹ˆë‹¤
- ëŒ€ì†Œë¬¸ìëŠ” êµ¬ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤

ì¡°íšŒ ê°€ëŠ¥í•œ ì˜ˆì‹œ: ë™ëŒ€*, ìœ ìœ *, ë˜¥íŒŒ*, ë³¸ì£½*, ë³¸*, ì›ì¡°*, í¬ë§*, í˜ì´*, Hì»¤*, ì¼€í‚¤*
"""
        
        # ìµœì‹  ë°ì´í„° ì„ íƒ (TA_YM ê¸°ì¤€)
        latest_result = result.sort_values(by='TA_YM', ascending=False).iloc[0]
        
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        store_name = latest_result.get('ê°€ë§¹ì ëª…', 'ì •ë³´ ì—†ìŒ')
        industry = latest_result.get('ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜', 'ì •ë³´ ì—†ìŒ')
        address = latest_result.get('HPSN_MCT_BZN_CD_NM', 'ì •ë³´ ì—†ìŒ')
        commercial_area = latest_result.get('HPSN_MCT_BZN_CD_NM', 'ë¹„ìƒê¶Œ')
        
        # ë§¤ì¶œ ê´€ë ¨ ì •ë³´
        revenue_level = latest_result.get('RC_M1_SAA', 'ì •ë³´ ì—†ìŒ')
        customer_count_level = latest_result.get('RC_M1_UE_CUS_CN', 'ì •ë³´ ì—†ìŒ')
        avg_amount_level = latest_result.get('RC_M1_AV_NP_AT', 'ì •ë³´ ì—†ìŒ')
        
        # ê³ ê° ë¹„ìœ¨ ì •ë³´
        new_customer_ratio = latest_result.get('MCT_UE_CLN_NEW_RAT', 0)
        revisit_ratio = latest_result.get('MCT_UE_CLN_REU_RAT', 0)
        resident_ratio = latest_result.get('RC_M1_SHC_RSD_UE_CLN_RAT', 0)
        delivery_ratio = latest_result.get('DLV_SAA_RAT', 0)
        
        # ìš´ì˜ ê¸°ê°„
        operation_period = latest_result.get('MCT_OPE_MS_CN', 'ì •ë³´ ì—†ìŒ')
        
        # ìµœì‹  ì›”
        latest_month = latest_result.get('TA_YM', 'ì •ë³´ ì—†ìŒ')
        
        # ê²€ìƒ‰ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
        report = f"""
======================================================================
      ğŸª ê°€ë§¹ì  ê¸°ë³¸ ì •ë³´ - '{store_name}' ê²€ìƒ‰ ê²°ê³¼
======================================================================

### ğŸ“‹ ê¸°ë³¸ ì •ë³´
- **ê°€ë§¹ì ëª…:** {store_name}
- **ì—…ì¢…:** {industry}
- **ìƒê¶Œ:** {commercial_area if pd.notna(commercial_area) else 'ë¹„ìƒê¶Œ'}
- **ìš´ì˜ ê¸°ê°„:** {operation_period}
- **ìµœì‹  ë°ì´í„°:** {latest_month}

### ğŸ’° ë§¤ì¶œ í˜„í™© (ìµœì‹ ì›” ê¸°ì¤€)
- **ë§¤ì¶œ ìˆ˜ì¤€:** {revenue_level}
- **ë°©ë¬¸ ê³ ê° ìˆ˜:** {customer_count_level}
- **ê°ë‹¨ê°€ ìˆ˜ì¤€:** {avg_amount_level}

### ğŸ‘¥ ê³ ê° ë¶„ì„ (ìµœì‹ ì›” ê¸°ì¤€)
- **ì‹ ê·œ ê³ ê° ë¹„ìœ¨:** {new_customer_ratio:.1f}%
- **ì¬ë°©ë¬¸ ê³ ê° ë¹„ìœ¨:** {revisit_ratio:.1f}%
- **ê±°ì£¼ ê³ ê° ë¹„ìœ¨:** {resident_ratio:.1f}%
- **ë°°ë‹¬ ë§¤ì¶œ ë¹„ìœ¨:** {delivery_ratio:.1f}%

### ğŸ” ì¶”ê°€ ë¶„ì„ ê°€ëŠ¥
ì´ ê°€ë§¹ì ì— ëŒ€í•´ ë” ìì„¸í•œ ë¶„ì„ì„ ì›í•˜ì‹œë©´ ë‹¤ìŒì„ ìš”ì²­í•´ì£¼ì„¸ìš”:
- **ë§ˆì¼€íŒ… ì „ëµ ë¶„ì„** (ì¹´í˜ ì—…ì¢…ì¸ ê²½ìš°)
- **ì¬ë°©ë¬¸ìœ¨ ê°œì„  ë°©ì•ˆ** (ì¬ë°©ë¬¸ìœ¨ì´ ë‚®ì€ ê²½ìš°)
- **ì „ì²´ì ì¸ ê°•ì /ì•½ì  ì§„ë‹¨**

======================================================================
"""
        
        return report
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return f"""ğŸš¨ ê°€ë§¹ì  ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ìƒì„¸ ì •ë³´:**
- ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}
- ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}
- ê²€ìƒ‰ì–´: {merchant_name}

**í•´ê²° ë°©ë²•:**
1. ê°€ë§¹ì ëª…ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
2. ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ê°€ë§¹ì  ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
3. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”

**ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:**
{error_details}"""

@tool
def store_strength_weakness_tool(store_id: str, df_all_join: pd.DataFrame) -> str:
    """
    ìš”ì‹ì—…ì¢… ê°€ë§¹ì ì˜ ì „ë°˜ì ì¸ ê±´ê°• ìƒíƒœë¥¼ ë‹¤ê°ë„ë¡œ ë¶„ì„í•˜ì—¬, 
    ê²½ìŸ ê·¸ë£¹ ëŒ€ë¹„ ëª…í™•í•œ ê°•ì ê³¼ ì•½ì ì„ ì§„ë‹¨í•˜ê³ , 
    ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì„  ì†”ë£¨ì…˜ì„ ì œì•ˆí•˜ëŠ” ë„êµ¬.
    ê°€ê²Œì˜ 'ë¬¸ì œì ', 'ê°€ì¥ í° ë¬¸ì œì ' ì— ëŒ€í•œ í¬ê´„ì ì¸ ì§„ë‹¨ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©ëœë‹¤.
    
    Args:
        store_id: ë¶„ì„í•  ê°€ë§¹ì  ID
        df_all_join: ì „ì²´ JOIN ë°ì´í„°
    
    Returns:
        ê°•ì /ì•½ì  ë¶„ì„ ë° ê°œì„  ì†”ë£¨ì…˜ ë¦¬í¬íŠ¸
    """
    try:
        store_df = df_all_join[df_all_join['ENCODED_MCT'] == store_id].tail(12)
        if store_df.empty:
            return f"ğŸš¨ ë¶„ì„ ë¶ˆê°€: '{store_id}' ê°€ë§¹ì ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        category, commercial_area = store_df[['ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜', 'HPSN_MCT_BZN_CD_NM']].iloc[0]
        
        if pd.notna(commercial_area):
            benchmark_type = "ë™ì¼ ìƒê¶Œ ë‚´ ë™ì¢…ì—…ê³„"
            benchmark_df = df_all_join[(df_all_join['ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜'] == category) & (df_all_join['HPSN_MCT_BZN_CD_NM'] == commercial_area)]
        else:
            benchmark_type = "ë¹„ìƒê¶Œ ì§€ì—­ì˜ ë™ì¢…ì—…ê³„"
            benchmark_df = df_all_join[(df_all_join['ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜'] == category) & (df_all_join['HPSN_MCT_BZN_CD_NM'].isna())]
        
        # ë¶„ì„í•  ì§€í‘œë“¤ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •)
        metrics_to_analyze = [
            {'name': 'ë§¤ì¶œ ê·œëª¨', 'col': 'RC_M1_SAA', 'type': 'tier', 'higher_is_better': False},
            {'name': 'ë°©ë¬¸ ê³ ê° ìˆ˜', 'col': 'RC_M1_UE_CUS_CN', 'type': 'tier', 'higher_is_better': False},
            {'name': 'ê³ ê°ë‹¹ ì§€ì¶œì•¡(ê°ë‹¨ê°€)', 'col': 'RC_M1_AV_NP_AT', 'type': 'tier', 'higher_is_better': False},
            {'name': 'ì—…ì¢… í‰ê·  ëŒ€ë¹„ ë§¤ì¶œ', 'col': 'M1_SME_RY_SAA_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ì‹ ê·œ ê³ ê° ë¹„ìœ¨', 'col': 'MCT_UE_CLN_NEW_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ì¬ë°©ë¬¸ ê³ ê° ë¹„ìœ¨', 'col': 'MCT_UE_CLN_REU_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ë°°ë‹¬ ë§¤ì¶œ ë¹„ìœ¨', 'col': 'DLV_SAA_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ê±°ì£¼ ê³ ê° ë¹„ìœ¨', 'col': 'RC_M1_SHC_RSD_UE_CLN_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ì§ì¥ì¸ ê³ ê° ë¹„ìœ¨', 'col': 'RC_M1_SHC_WP_UE_CLN_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ìœ ë™ì¸êµ¬ ê³ ê° ë¹„ìœ¨', 'col': 'RC_M1_SHC_FLP_UE_CLN_RAT', 'type': 'ratio', 'higher_is_better': True},
        ]

        # ë°°ë‹¬ ë°ì´í„° í™•ì¸
        has_delivery_data = store_df['DLV_SAA_RAT'].sum() > 0
        if not has_delivery_data:
            metrics_to_analyze = [m for m in metrics_to_analyze if m['name'] != 'ë°°ë‹¬ ë§¤ì¶œ ë¹„ìœ¨']

        all_scores = []
        for metric in metrics_to_analyze:
            if metric['type'] == 'tier':
                # tier íƒ€ì…ì€ í…ìŠ¤íŠ¸ ê°’ì´ë¯€ë¡œ ìˆ«ìë¡œ ë³€í™˜
                store_val = get_score_from_raw(store_df[metric['col']].iloc[-1]) if not store_df.empty else np.nan
                benchmark_series = benchmark_df[metric['col']].apply(get_score_from_raw)
            else:
                # ratio íƒ€ì…ì€ ìˆ«ì ê°’
                store_val = store_df[metric['col']].mean()
                benchmark_series = benchmark_df.groupby('ENCODED_MCT')[metric['col']].mean()
            
            score = get_percentile_score(store_val, benchmark_series, metric['higher_is_better'])
            
            store_display, benchmark_display = "", ""
            if metric['type'] == 'ratio':
                store_display = f"{store_val:.1%}"
                benchmark_display = f"{benchmark_series.mean():.1%}"
            elif metric['type'] == 'tier':
                store_display = store_df[metric['col']].iloc[-1] if not store_df.empty else "N/A"
                benchmark_display = benchmark_df[metric['col']].mode()[0] if not benchmark_df.empty and not benchmark_df[metric['col']].mode().empty else "N/A"

            all_scores.append({
                'metric': metric['name'], 
                'score': f"{score:.1f}ì ",
                'store_value_display': store_display,
                'benchmark_value_display': benchmark_display
            })

        # ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„
        demo_cols = [col for col in df_all_join.columns if ('MAL' in col or 'FME' in col) and 'RAT' in col]
        area_detailed_profile = benchmark_df[demo_cols].mean()
        store_detailed_profile = store_df[demo_cols].mean()
        area_top2, store_top2 = area_detailed_profile.nlargest(2), store_detailed_profile.nlargest(2)

        match_score = calculate_advanced_match_score(area_top2.index.tolist(), store_top2.index.tolist())
        all_scores.append({
            'metric': 'ìƒê¶Œ-ê³ ê° ì í•©ë„', 
            'score': f"{match_score:.1f}ì ",
            'store_value_display': f"Top 2: {[n.replace('M12_','').replace('_RAT','') for n in store_top2.index.tolist()]}",
            'benchmark_value_display': f"Top 2: {[n.replace('M12_','').replace('_RAT','') for n in area_top2.index.tolist()]}"
        })
        
        # ê°•ì ê³¼ ì•½ì  ë¶„ë¥˜
        strengths = [r for r in all_scores if float(r['score'].replace('ì ','')) > 80]
        weaknesses = [r for r in all_scores if (r['metric'] != 'ìƒê¶Œ-ê³ ê° ì í•©ë„' and float(r['score'].replace('ì ','')) < 20) or \
                                           (r['metric'] == 'ìƒê¶Œ-ê³ ê° ì í•©ë„' and float(r['score'].replace('ì ','')) < 40)]
        
        if not weaknesses and all_scores:
            weakest_link = min(all_scores, key=lambda x: float(x['score'].replace('ì ','')))
            weaknesses.append(weakest_link)
            
        # ì •ë ¬
        sorted_strengths = sorted(strengths, key=lambda x: float(x['score'].split('ì ')[0]), reverse=True)
        sorted_weaknesses = sorted(weaknesses, key=lambda x: float(x['score'].split('ì ')[0]))

        # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        final_report = f"""
======================================================================
      ğŸ“Š AI ì „ë°©ìœ„ ì§„ë‹¨ - '{store_id}' ê°€ë§¹ì  ê±´ê°•ë„ ë¶„ì„ ë¦¬í¬íŠ¸
======================================================================

### ğŸ“ˆ ë¶„ì„ ê°œìš”

* **ë¶„ì„ ëŒ€ìƒ:** {store_id}
* **ë¶„ì„ ê¸°ì¤€:** {benchmark_type} (ìµœê·¼ 12ê°œì›” ë°ì´í„°)
* **ì—…ì¢…/ìƒê¶Œ:** {category} / {commercial_area if pd.notna(commercial_area) else 'ë¹„ìƒê¶Œ'}

### âœ… ê°•ì  ìš”ì•½ (Top 3)

"""
        
        if sorted_strengths:
            for i, s in enumerate(sorted_strengths[:3], 1):
                score = float(s['score'].replace('ì ',''))
                interpretation = f"ê²½ìŸì  ëŒ€ë¹„ ìƒìœ„ {100-score:.0f}% ìˆ˜ì¤€ì˜ ë›°ì–´ë‚œ ì„±ê³¼"
                final_report += f"""
**{i}. {s['metric']} (ê±´ê°• ì ìˆ˜: {s['score']})**
- í•´ì„: {interpretation}
- ë°ì´í„°: ìš°ë¦¬ ê°€ê²Œ({s['store_value_display']}) vs ê²½ìŸì ({s['benchmark_value_display']})
"""
        else:
            final_report += "íŠ¹ë³„í•œ ê°•ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"

        final_report += """
### âŒ ì•½ì  ìš”ì•½ (Top 3)

"""
        
        if sorted_weaknesses:
            for i, w in enumerate(sorted_weaknesses[:3], 1):
                score = float(w['score'].replace('ì ',''))
                interpretation = f"ê²½ìŸì  ëŒ€ë¹„ í•˜ìœ„ {score:.0f}% ìˆ˜ì¤€ìœ¼ë¡œ ê°œì„ ì´ í•„ìš”í•¨" if score < 40 else "ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•˜ë‚˜ ìƒëŒ€ì ìœ¼ë¡œ ì•„ì‰¬ìš´ ì§€í‘œ"
                final_report += f"""
**{i}. {w['metric']} (ê±´ê°• ì ìˆ˜: {w['score']})**
- í•´ì„: {interpretation}
- ë°ì´í„°: ìš°ë¦¬ ê°€ê²Œ({w['store_value_display']}) vs ê²½ìŸì ({w['benchmark_value_display']})
"""
        else:
            final_report += "íŠ¹ë³„í•œ ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"

        final_report += """
### ğŸš€ ì¢…í•© ì§„ë‹¨ ë° ê°œì„  ì†”ë£¨ì…˜

**í•µì‹¬ ë¬¸ì œ ì§„ë‹¨:**
"""
        
        if sorted_weaknesses:
            main_weakness = sorted_weaknesses[0]
            final_report += f"- ê°€ì¥ ì‹œê¸‰í•œ ê°œì„  ê³¼ì œ: {main_weakness['metric']}\n"
            final_report += f"- í˜„ì¬ ìˆ˜ì¤€: {main_weakness['store_value_display']}\n"
            final_report += f"- ëª©í‘œ ìˆ˜ì¤€: {main_weakness['benchmark_value_display']}\n"
        else:
            final_report += "- ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤.\n"

        final_report += """
**ë§ˆì¼€íŒ… ì œì•ˆ:**

1. **ê°•ì  í™œìš© ì „ëµ**
   - í˜„ì¬ ì˜í•˜ê³  ìˆëŠ” ë¶€ë¶„ì„ ë”ìš± ê°•í™”í•˜ì—¬ ê²½ìŸ ìš°ìœ„ í™•ë³´
   - ê°•ì ì„ ë§ˆì¼€íŒ… í¬ì¸íŠ¸ë¡œ í™œìš©í•œ ì°¨ë³„í™” ì „ëµ

2. **ì•½ì  ë³´ì™„ ì „ëµ**
   - ê°€ì¥ ì•½í•œ ë¶€ë¶„ë¶€í„° ë‹¨ê³„ì ìœ¼ë¡œ ê°œì„ 
   - ì„±ê³µ ì‚¬ë¡€ ë²¤ì¹˜ë§ˆí‚¹ì„ í†µí•œ ë¹ ë¥¸ ê°œì„ 

3. **í†µí•© ìµœì í™” ì „ëµ**
   - ê°•ì ê³¼ ì•½ì ì˜ ì‹œë„ˆì§€ íš¨ê³¼ ì°½ì¶œ
   - ê³ ê° ê²½í—˜ ì „ë°˜ì˜ í’ˆì§ˆ í–¥ìƒ

### ğŸ’¡ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ í”Œëœ

1. **1ì£¼ì°¨: ê¸´ê¸‰ ê°œì„ **
   - ê°€ì¥ ì•½í•œ ì§€í‘œ 1ê°œì— ì§‘ì¤‘í•œ ì¦‰ì‹œ ê°œì„  ì¡°ì¹˜

2. **2-4ì£¼ì°¨: ë‹¨ê³„ì  ê°œì„ **
   - ë‚˜ë¨¸ì§€ ì•½ì ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ê°œì„ 
   - ê°•ì ì„ ë”ìš± ê°•í™”í•˜ëŠ” ì „ëµ ì‹¤í–‰

3. **1-3ê°œì›”: ì§€ì†ì  ìµœì í™”**
   - ì„±ê³¼ ì¸¡ì • ë° ì „ëµ ì¡°ì •
   - ì¥ê¸°ì ì¸ ê²½ìŸë ¥ í™•ë³´

"""
        return final_report

    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return f"""ğŸš¨ ì „ë°©ìœ„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ìƒì„¸ ì •ë³´:**
- ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}
- ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}
- ê°€ë§¹ì  ID: {store_id}

**í•´ê²° ë°©ë²•:**
1. ê°€ë§¹ì  IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
2. ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ê°€ë§¹ì  ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
3. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”

**ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:**
{error_details}"""
