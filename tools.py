"""
AI ë¹„ë°€ìƒë‹´ì‚¬ ë¶„ì„ ë„êµ¬ ëª¨ìŒ
3ê°œì˜ ë…ë¦½ì ì¸ ë¶„ì„ ëª¨ë¸ì„ LangChain Toolë¡œ ë¦¬íŒ©í† ë§
"""

import pandas as pd
import numpy as np
import requests
import json
from typing import Dict, Any, List, Tuple
from langchain_core.tools import tool

# =============================================================================
# ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =============================================================================

def get_score_from_raw(raw_value):
    """ì›ì‹œ ê°’ì„ ì ìˆ˜ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    if pd.isna(raw_value):
        return np.nan
    raw_str = str(raw_value)
    score_map = {"10%ì´í•˜": 6, "10-25%": 5, "25-50%": 4, "50-75%": 3, "75-90%": 2, "90%ì´ˆê³¼": 1}
    for key, score in score_map.items():
        if key in raw_str:
            return score
    return np.nan

def translate_metric(metric_type, raw_value):
    """ì§€í‘œë¥¼ ì‚¬ëŒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if pd.isna(raw_value):
        return "ì •ë³´ ì—†ìŒ"
    translation_map = {
        "tenure": {"10%ì´í•˜": "ìƒìœ„ 10% ì´ë‚´ (ê°€ì¥ ì˜¤ë˜ ìš´ì˜)", "10-25%": "ìƒìœ„ 10-25%", "25-50%": "ì¤‘ìƒìœ„ 25-50%", "50-75%": "ì¤‘í•˜ìœ„ 50-75%", "75-90%": "í•˜ìœ„ 10-25%", "90%ì´ˆê³¼": "í•˜ìœ„ 10% ì´ë‚´ (ê°€ì¥ ìµœê·¼ ì‹œì‘)"},
        "level": {"10%ì´í•˜": "ìƒìœ„ 10% ì´ë‚´ (ê°€ì¥ ë†’ìŒ)", "10-25%": "ìƒìœ„ 10-25%", "25-50%": "ì¤‘ìƒìœ„ 25-50%", "50-75%": "ì¤‘í•˜ìœ„ 50-75%", "75-90%": "í•˜ìœ„ 10-25%", "90%ì´ˆê³¼": "í•˜ìœ„ 10% ì´ë‚´ (ê°€ì¥ ë‚®ìŒ)"}
    }
    explanation_map = translation_map.get(metric_type, {})
    for key, explanation in explanation_map.items():
        if key in str(raw_value):
            return f"{raw_value} ({explanation})"
    return str(raw_value)

def score_to_level_text(score):
    """ì ìˆ˜ë¥¼ ë ˆë²¨ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if pd.isna(score):
        return "ì •ë³´ ì—†ìŒ"
    if score >= 5.5:
        return "ìµœìƒìœ„ 10% ìˆ˜ì¤€"
    if score >= 4.5:
        return "ìƒìœ„ 10-25% ìˆ˜ì¤€"
    if score >= 3.5:
        return "ì¤‘ìƒìœ„ 25-50% ìˆ˜ì¤€"
    if score >= 2.5:
        return "ì¤‘í•˜ìœ„ 50-75% ìˆ˜ì¤€"
    if score >= 1.5:
        return "í•˜ìœ„ 10-25% ìˆ˜ì¤€"
    return "í•˜ìœ„ 10% ìˆ˜ì¤€"

# =============================================================================
# ëª¨ë¸ 1: ì¹´í˜ ì—…ì¢… ì£¼ìš” ê³ ê° ë¶„ì„ ë° ë§ˆì¼€íŒ… ì±„ë„/í™ë³´ì•ˆ ì¶”ì²œ
# =============================================================================

# AIì˜ ì§€ì‹ ë² ì´ìŠ¤ - í˜ë¥´ì†Œë‚˜ ë§µ
PERSONA_MAP = {
    'M12_FME_1020_RAT': {'name': 'ë””ì§€í„¸ íë ˆì´í„°', 'desc': '10-20ëŒ€ ì—¬ì„±', 'features': 'SNS ê³µìœ ë¥¼ í†µí•œ ì •ì²´ì„± í˜•ì„±, ë””í†  ì†Œë¹„, ê°€ì„±ë¹„ì™€ ê°€ì‹¬ë¹„ì˜ ì „ëµì  í˜¼í•©'},
    'M12_MAL_1020_RAT': {'name': 'íŠ¸ë Œë“œ ê²€ì¦ê°€', 'desc': '10-20ëŒ€ ë‚¨ì„±', 'features': 'ì˜¨ë¼ì¸ íŠ¸ë Œë“œì˜ ì˜¤í”„ë¼ì¸ ê²½í—˜ ë° ê²€ì¦, ê°€ì„±ë¹„ ì¤‘ì‹œ, ë² ì´ìŠ¤ìº í”„ë¡œì„œì˜ ê³µê°„ í™œìš©'},
    'M12_FME_30_RAT': {'name': 'ì „ëµì  ìµœì í™” ì „ë¬¸ê°€', 'desc': '30ëŒ€ ì—¬ì„±', 'features': 'ì‹œê°„/ë¹„ìš©/ì—ë„ˆì§€ì˜ ìµœì í™”, ê°€ì¹˜ ê²½í—˜ ê·¹ëŒ€í™”, ë¶„ì´ˆì‚¬íšŒ'},
    'M12_MAL_30_RAT': {'name': 'íš¨ìœ¨ ì¶”êµ¬ í”„ë¡œí˜ì…”ë„', 'desc': '30ëŒ€ ë‚¨ì„±', 'features': 'ì—…ë¬´ì™€ ì¼ìƒ ì† ëª¨ë“  ì ‘ì ì—ì„œ ì‹œê°„ê³¼ ë…¸ë ¥ ì ˆì•½, ê¸°ëŠ¥ì  ì†Œë¹„'},
    'M12_FME_40_RAT': {'name': 'ê°€ì¡± ì›°ë¹™ ì„¤ê³„ì', 'desc': '40ëŒ€ ì—¬ì„±', 'features': 'ê°€ì¡±ì˜ ê±´ê°•ê³¼ ê²½í—˜ì— ëŒ€í•œ í”„ë¦¬ë¯¸ì—„ ê°€ì¹˜ íˆ¬ì, ì»¤ë®¤ë‹ˆí‹° ì •ë³´ êµë¥˜'},
    'M12_MAL_40_RAT': {'name': 'ì•ˆì • ì¶”êµ¬ ë¦¬ë”', 'desc': '40ëŒ€ ë‚¨ì„±', 'features': 'ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë¸Œëœë“œë¥¼ í†µí•œ ìœ„í—˜ ìµœì†Œí™”, ê²€ì¦ëœ í’ˆì§ˆ ì„ í˜¸'},
    'M12_FME_50_RAT': {'name': 'ì»¤ë®¤ë‹ˆí‹° ì•µì»¤', 'desc': '50ëŒ€ ì—¬ì„±', 'features': 'ì‚¬íšŒì  ê´€ê³„ë§ì˜ ì¤‘ì‹¬ìœ¼ë¡œì„œ ì†Œí†µê³¼ êµë¥˜ ì£¼ë„, í¸ì•ˆí•¨ê³¼ ê´€ê³„ ì¤‘ì‹œ'},
    'M12_MAL_50_RAT': {'name': 'ë¡œì»¬ í—ˆë¸Œ', 'desc': '50ëŒ€ ë‚¨ì„±', 'features': 'ë‹¨ê³¨ ë¬¸í™”ë¥¼ í†µí•´ ì§€ì—­ ì»¤ë®¤ë‹ˆí‹°ì˜ êµ¬ì‹¬ì  ì—­í• , ìµìˆ™í•¨ ì„ í˜¸'},
    'M12_FME_60_RAT': {'name': 'ì›°ë‹ˆìŠ¤ ë¼ì´í”„ ì¶”êµ¬ì', 'desc': '60ëŒ€ ì´ìƒ ì—¬ì„±', 'features': 'ì‹ ì²´ì /ì •ì„œì  ì›°ë¹™ì„ ìœ„í•œ ì ê·¹ì ì¸ ì†Œë¹„ì™€ í™œë™'},
    'M12_MAL_60_RAT': {'name': 'ê²½í—˜ ê°€ì¹˜ íˆ¬ìì', 'desc': '60ëŒ€ ì´ìƒ ë‚¨ì„±', 'features': 'ì¶•ì ëœ ìì‚°ì„ í†µí•´ ê´€ê³„ì™€ ì˜ë¯¸ ìˆëŠ” ê²½í—˜ì— íˆ¬ì'}
}

@tool
def cafe_marketing_tool(store_id: str, df_all_join: pd.DataFrame, df_prompt_dna: pd.DataFrame) -> str:
    """
    ì¹´í˜ ì—…ì¢… ê°€ë§¹ì ì˜ ì£¼ìš” ë°©ë¬¸ ê³ ê° íŠ¹ì„±ì„ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ê³ , 
    ê°€ì¥ íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ… ì±„ë„ê³¼ êµ¬ì²´ì ì¸ í™ë³´ ë¬¸êµ¬ë¥¼ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ ë„êµ¬.
    'ì¹´í˜', 'ê³ ê° ë¶„ì„', 'í™ë³´' ê´€ë ¨ ì§ˆë¬¸ì— ì‚¬ìš©ëœë‹¤.
    
    Args:
        store_id: ë¶„ì„í•  ê°€ë§¹ì  ID
        df_all_join: ì „ì²´ JOIN ë°ì´í„°
        df_prompt_dna: AIìƒë‹´ì‚¬ í•µì‹¬ì „ëµ í”„ë¡¬í”„íŠ¸ ë°ì´í„°
    
    Returns:
        ë¶„ì„ ê²°ê³¼ ë° ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆ ë¦¬í¬íŠ¸
    """
    try:
        # 1ë‹¨ê³„: ë°ì´í„° ë¶„ì„ ì—”ì§„
        # [ìˆ˜ì •] ë™ì  ê³ ê° ë¶„ì„ ë¡œì§
        persona_columns = list(PERSONA_MAP.keys())

        # ì „ì²´ ë°ì´í„°ì—ì„œ í•´ë‹¹ ê°€ë§¹ì  & 'ì¹´í˜' ì—…ì¢… ë°ì´í„° í•„í„°ë§
        store_df = df_all_join[(df_all_join['ENCODED_MCT'] == store_id) & (df_all_join['ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜'] == 'ì¹´í˜')].copy()

        if store_df.empty:
            return f"ë¶„ì„ ì‹¤íŒ¨: '{store_id}' ê°€ë§¹ì ì€ 'ì¹´í˜' ì—…ì¢…ì´ ì•„ë‹ˆê±°ë‚˜, ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # í•´ë‹¹ ê°€ë§¹ì ì˜ ê¸°ê°„ë³„ ê³ ê° ë¹„ì¤‘ ë°ì´í„°ì—ì„œ í‰ê·  ê³„ì‚°
        analysis_df = store_df[persona_columns]
        # analysis_df.replace(-999999.9, np.nan, inplace=True) # ì›ë³¸ ë°ì´í„° ë¡œë”© ì‹œ ì´ë¯¸ ì²˜ë¦¬ë¨
        store_persona_data = analysis_df.mean()
        
        max_value = store_persona_data.max()
        threshold = max_value - 5.0
        
        top_segments = store_persona_data[store_persona_data >= threshold]
        
        # ê²°ê³¼ê°€ 2ê°œë¥¼ ì´ˆê³¼í•  ê²½ìš°, ê°€ì¥ ë†’ì€ ìƒìœ„ 2ê°œë§Œ ì„ íƒ
        if len(top_segments) > 2:
            top_segments = top_segments.sort_values(ascending=False).head(2)
            
        if top_segments.empty:
            return f"ë¶„ì„ ì‹¤íŒ¨: '{store_id}' ê°€ë§¹ì ì˜ ìœ íš¨í•œ ì£¼ìš” ê³ ê°ì¸µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        main_personas_info = [PERSONA_MAP[seg] for seg in top_segments.index]
        main_personas_str = ", ".join([f"{p['name']}({p['desc']})" for p in main_personas_info])
        
        # [ì¶”ê°€] ì£¼ìš” ê³ ê° í˜ë¥´ì†Œë‚˜ íŠ¹ì§• ì„¤ëª… ìƒì„±
        main_personas_details_list = []
        for p in main_personas_info:
            detail = f"  - **{p['name']} ({p['desc']})**: {p['features']}"
            main_personas_details_list.append(detail)
        main_personas_details_str = "\n".join(main_personas_details_list)
        
        # í•µì‹¬ ì„±ê³µ ì „ëµ ë¶„ì„
        store_data = df_all_join[df_all_join['ENCODED_MCT'] == store_id]
        if store_data.empty:
            return f"ë¶„ì„ ì‹¤íŒ¨: '{store_id}' ê°€ë§¹ì ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        latest_data = store_data.sort_values(by='TA_YM', ascending=False).iloc[0]
        store_commercial_area = latest_data['HPSN_MCT_BZN_CD_NM']
        
        if pd.isna(store_commercial_area):
            store_commercial_area = 'ë¹„ìƒê¶Œ'
        
        dna_row = df_prompt_dna[(df_prompt_dna['ìƒê¶Œ'] == store_commercial_area) & (df_prompt_dna['ì—…ì¢…'] == 'ì¹´í˜')]
        if dna_row.empty:
            return f"ë¶„ì„ ì‹¤íŒ¨: '{store_commercial_area}' ìƒê¶Œì˜ 'ì¹´í˜' ì—…ì¢… ì„±ê³µ DNAë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        core_strategy = dna_row['í•µì‹¬ê²½ì˜ì „ëµ'].iloc[0]

        # 2ë‹¨ê³„: LLM í˜¸ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt_for_gemini = f"""
# MISSION
ë„ˆëŠ” **'ê³ ê° ì‹¬ë¦¬ ë¶„ì„ê°€'ì´ì 'ì „ëµ ì»¨ì„¤í„´íŠ¸'**ì˜ ì—­ëŸ‰ì„ ê²¸ë¹„í•œ 'AI ë¹„ë°€ìƒë‹´ì‚¬'ì•¼. ë„ˆì˜ ìµœìš°ì„  ì„ë¬´ëŠ” **ì‚¬ì¥ë‹˜ ê°€ê²Œì˜ í•µì‹¬ ê³ ê°(WHO)ì„ ì™„ë²½í•˜ê²Œ ì´í•´í•˜ê³ , ê·¸ë“¤ì˜ ë§ˆìŒì„ ì‚¬ë¡œì¡ëŠ” ê²ƒì„ ëª¨ë“  ì „ëµì˜ ì¶œë°œì ì´ì ìµœì¢… ëª©ì ì§€**ë¡œ ì‚¼ëŠ” ê²ƒì´ë‹¤. ê°€ê²Œì˜ ì„±ê³µ ì „ëµ(WHAT)ì€ ê³ ê°ì˜ ë§ˆìŒì„ ì–»ê¸° ìœ„í•œ 'ê°€ì¥ íš¨ê³¼ì ì´ê³  ì°¨ë³„í™”ëœ ë°©ë²•'ì„ ê²°ì •í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤.

---

# DATA INPUT (ë„ˆê°€ ë¶„ì„í•  í•µì‹¬ ë°ì´í„°)
1. **[WHO] ìš°ë¦¬ ê°€ê²Œ í•µì‹¬ ê³ ê° í˜ë¥´ì†Œë‚˜ (ê°€ì¥ ì¤‘ìš”í•œ ê¸°ì¤€ì ):**
{main_personas_details_list}

2. **[WHAT] ìš°ë¦¬ ê°€ê²Œì˜ ì‹œì¥ ì„±ê³µ ì „ëµ (ê³ ê°ì„ ê³µëµí•  ìš°ë¦¬ë§Œì˜ ë¬´ê¸°):**
- '{core_strategy}'

---

# CORE TASK: The Art of Fusion (WHO-First ì ‘ê·¼ë²•)

ë„ˆëŠ” ê²°ê³¼ë¬¼ì„ ë§Œë“¤ê¸° ì „ì—, ì•„ë˜ì˜ ì‚¬ê³  ê³¼ì •ì„ ë°˜ë“œì‹œ ê±°ì³ì•¼ í•œë‹¤. ì´ê²ƒì´ ëª¨ë“  ì œì•ˆì˜ ë…¼ë¦¬ì  ê¸°ë°˜ì´ë‹¤.

**[ì‚¬ê³  ê³¼ì •: ê³¼ë…ê³¼ í™”ì‚´]**
1.  **ê³¼ë… ì„¤ì • (Target):** ê³ ê°(WHO)ì˜ ë§ˆìŒì„ 'ê³¼ë…'ìœ¼ë¡œ ì„¤ì •í•œë‹¤. ê·¸ë“¤ì˜ ê°€ì¥ ê¹Šì€ ìš•ë§, ìì£¼ ëŠë¼ëŠ” ì¦ê±°ì›€ì´ë‚˜ ë¶ˆí¸í•¨ì´ ë°”ë¡œ ê³¼ë…ì˜ 'ì •ì¤‘ì•™(Bullseye)'ì´ë‹¤.
2.  **íŠ¹ë³„í•œ í™”ì‚´ ì„ íƒ (Arrow):** ê°€ê²Œì˜ ì„±ê³µ ì „ëµ(WHAT)ì„ ì´ ê³¼ë…ì˜ ì •ì¤‘ì•™ì„ ê¿°ëš«ê¸° ìœ„í•œ 'ê°€ì¥ íŠ¹ë³„í•˜ê³  ë‚ ì¹´ë¡œìš´ í™”ì‚´'ë¡œ ì„ íƒí•œë‹¤.
3.  **í•„ìŠ¹ ê°ë„ ë°œê²¬:** ìµœì¢…ì ìœ¼ë¡œ ë„ˆê°€ ì œì•ˆí•  ëª¨ë“  ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ëŠ”, **"ì–´ë–¤ 'íŠ¹ë³„í•œ í™”ì‚´(WHAT)'ì„ ì‚¬ìš©í•´ì„œ 'ê³ ê°(WHO)ì´ë¼ëŠ” ê³¼ë…'ì˜ ì •ì¤‘ì•™ì„ ê°€ì¥ ì •í™•í•˜ê²Œ ë§ì¶œ ê²ƒì¸ê°€?"**ì— ëŒ€í•œ ëŒ€ë‹µì´ ë˜ì–´ì•¼ í•œë‹¤.

---

# OUTPUT INSTRUCTION (ì•„ë˜ ì§€ì‹œì‚¬í•­ê³¼ í˜•ì‹ì„ ì—„ê²©í•˜ê²Œ ë”°ë¼ì„œ ê²°ê³¼ë¬¼ì„ ìƒì„±í•´ì¤˜)

## 1. ì „ì²´ í†¤ì•¤ë§¤ë„ˆ
- **ê³ ê° ì¤‘ì‹¬ì˜ ì¡°ì–¸ê°€:** ëª¨ë“  ì„¤ëª…ê³¼ ì œì•ˆì˜ ì£¼ì–´ë¥¼ 'ê³ ê°'ìœ¼ë¡œ ì‚¼ì•„, ì‚¬ì¥ë‹˜ì´ ê³ ê°ì˜ ì…ì¥ì—ì„œ ìƒê°í•˜ë„ë¡ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•´ì¤˜.
- **ë…¼ë¦¬ì  ìŠ¤í† ë¦¬í…”ëŸ¬:** 'ê³ ê°ì€ ~ì„ ì›í•˜ê¸° ë•Œë¬¸ì—(WHO) â†’ ìš°ë¦¬ ê°€ê²ŒëŠ” ~ë°©ì‹ìœ¼ë¡œ(WHAT) â†’ ì´ë ‡ê²Œ ë‹¤ê°€ê°€ì•¼ í•©ë‹ˆë‹¤' ë¼ëŠ” ëª…í™•í•œ ë…¼ë¦¬ì  íë¦„ìœ¼ë¡œ ìŠ¤í† ë¦¬ë¥¼ ì „ê°œí•´ì¤˜.

## 2. ìµœì¢… ê²°ê³¼ë¬¼ í˜•ì‹ (ì´ êµ¬ì¡°ë¥¼ ì™„ë²½í•˜ê²Œ ë”°ë¼ì¤˜)

**(ê³ ê°ì— ëŒ€í•œ ê¹Šì€ ì´í•´ë¥¼ ê°•ì¡°í•˜ë©°, ë”°ëœ»í•œ ì¸ì‚¬ë§ë¡œ ì‹œì‘)**

---

**1. ìš°ë¦¬ ê°€ê²Œì˜ ì‹¬ì¥ì„ ë›°ê²Œ í•  ë°”ë¡œ ê·¸ 'ê³ ê°'ì…ë‹ˆë‹¤! (ê³ ê° í˜ë¥´ì†Œë‚˜ ì‹¬ì¸µ ë¶„ì„)**
(DATAì˜ [WHO]ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì´ ê³ ê°ë“¤ì´ 'ì™œ' ìš°ë¦¬ ì¹´í˜ë¥¼ ì°¾ëŠ”ì§€, ê·¸ë“¤ì˜ ì¼ìƒê³¼ ìš•ë§ì„ ê¹Šì´ ìˆê²Œ íŒŒê³ ë“¤ì–´ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•´ì¤˜.)

**2. ì´ ê³ ê°ë“¤ì„ ì‚¬ë¡œì¡ì„ ìš°ë¦¬ ê°€ê²Œë§Œì˜ 'ë¹„ë°€ ë¬´ê¸°'ì…ë‹ˆë‹¤! (í•µì‹¬ ì„±ê³µ ì „ëµ)**
(DATAì˜ [WHAT]ì„ ë°”íƒ•ìœ¼ë¡œ, ì´ ì „ëµì´ ì™œ (1)ë²ˆ ê³ ê°ë“¤ì˜ ë§ˆìŒì„ ì–»ëŠ” ë° ê°€ì¥ íš¨ê³¼ì ì¸ 'ë¬´ê¸°'ê°€ ë  ìˆ˜ ìˆëŠ”ì§€ ê·¸ ì´ìœ ë¥¼ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì¤˜.)

---

**(ë‘ ë°ì´í„°ë¥¼ ìœµí•©í•˜ëŠ” ë¸Œë¦¿ì§€ ì—­í• ì˜ íŒŒíŠ¸)**
**3. ê³ ê°ì˜ ë§ˆìŒì„ í–¥í•œ 'í•„ìŠ¹ì˜ ê°ë„'ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!**
(ìœ„ 'ê³¼ë…ê³¼ í™”ì‚´' ì‚¬ê³  ê³¼ì •ì˜ ê²°ê³¼ë¥¼ ì—¬ê¸°ì„œ ê³µê°œí•´ì¤˜. **"(1)ë²ˆ ê³ ê°ì˜ ë§ˆìŒ(ê³¼ë…)ì„ ì‚¬ë¡œì¡ê¸° ìœ„í•´, (2)ë²ˆ ì „ëµ(í™”ì‚´)ì„ í™œìš©í•˜ëŠ” ê²ƒì´ ì™œ ìµœì ì˜ ì¡°í•©ì¸ì§€"**ë¥¼ ì•Œê¸° ì‰½ê²Œ ì„¤ëª…í•´ì¤˜. ì´ê²ƒì´ ì•ìœ¼ë¡œ ì´ì–´ì§ˆ ëª¨ë“  ë§ˆì¼€íŒ… ì œì•ˆì˜ í•µì‹¬ ë…¼ë¦¬ê°€ ë  ê±°ì•¼.)

---

**4. 'í•„ìŠ¹ì˜ ê°ë„'ë¡œ ê³ ê°ì˜ ë§ˆìŒì— ë‹¤ê°€ê°ˆ ì‹¤ì „ ì „ëµì…ë‹ˆë‹¤!**
(ì´ì œ ì•ì„œ ì •ì˜í•œ 'í•„ìŠ¹ì˜ ê°ë„'ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì² ì €íˆ ê³ ê° ì¤‘ì‹¬ì ì¸ ë§ˆì¼€íŒ… ì „ëµì„ ì œì•ˆ ì‹œì‘)

**ğŸ“ˆ ì¶”ì²œ ë§ˆì¼€íŒ… ì±„ë„**
(ê³ ê°(WHO)ì´ ê°€ì¥ ë§ì€ ì‹œê°„ì„ ë³´ë‚´ê³ , ê°€ì¥ ì‹ ë¢°í•˜ëŠ” ì±„ë„ì„ ì œì•ˆí•˜ëŠ” ê²ƒì´ ìµœìš°ì„  ê¸°ì¤€)

* **[ì±„ë„ ì´ë¦„]:**
    * **ê·¼ê±°:**
        1. **(ê³ ê° ê´€ì ):** ì´ ì±„ë„ì´ ì™œ **(1)ë²ˆ ê³ ê°**ì˜ ë¼ì´í”„ìŠ¤íƒ€ì¼ê³¼ ì •ë³´ ì†Œë¹„ ë°©ì‹ì— ì™„ë²½í•˜ê²Œ ë¶€í•©í•˜ëŠ”ì§€ë¥¼ ë¨¼ì € ì„¤ëª….
        2. **(ì „ëµ ê´€ì ):** ê·¸ ë‹¤ìŒ, **(2)ë²ˆ ì „ëµ**ì„ í™œìš©í–ˆì„ ë•Œ ì´ ì±„ë„ì—ì„œ ì–´ë–¤ ì°¨ë³„í™”ëœ ë§¤ë ¥ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë§ë¶™ì—¬ ì„¤ëª….

**ğŸ’¡ ì¶”ì²œ í™ë³´ ë°©ì•ˆ**
(ëª¨ë“  ì•„ì´ë””ì–´ëŠ” 'ê³ ê°ì´ ë¬´ì—‡ì„ ê²½í—˜í•˜ê³  ì‹¶ì„ê¹Œ?'ë¼ëŠ” ì§ˆë¬¸ì—ì„œ ì¶œë°œí•´ì•¼ í•¨)

**[ë²ˆí˜¸]. [ê³ ê°ì˜ ìš•êµ¬ë¥¼ ìê·¹í•˜ëŠ” ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ ì œëª©]**
* **ë¬´ì—‡ì„ (What):** (ì´ ì•„ì´ë””ì–´ë¥¼ í†µí•´ ê³ ê°ì´ ì–´ë–¤ 'íŠ¹ë³„í•œ ê²½í—˜ê³¼ ê°ì •'ì„ ì–»ê²Œ ë ì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½)
* **ì–´ë–»ê²Œ (How):** (ì‚¬ì¥ë‹˜ì´ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ë°©ë²•ë“¤ì„ ê³ ê°ì˜ ì…ì¥ì—ì„œ ë§¤ë ¥ì ìœ¼ë¡œ ëŠë‚„ë§Œí•œ ì˜ˆì‹œì™€ í•¨ê»˜ ìƒì„¸í•˜ê²Œ ì œì‹œ)
* **ê·¼ê±° (Why):** (ê°€ì¥ ì¤‘ìš”! ì•„ë˜ ë‘ ë‹¨ê³„ì˜ ë…¼ë¦¬ë¡œ ì¦ëª…)
    1.  **[1ìˆœìœ„-ê³ ê° ë§Œì¡±]:** ë¨¼ì €, ì´ ì•„ì´ë””ì–´ê°€ **(1)ë²ˆ ê³ ê°**ì˜ ì–´ë–¤ ìš•êµ¬ì™€ ì‹¬ë¦¬ë¥¼ ì •í™•íˆ ì¶©ì¡±ì‹œì¼œ **'ê°€ê³  ì‹¶ë‹¤', 'í•˜ê³  ì‹¶ë‹¤'**ëŠ” ë§ˆìŒì„ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ëŠ”ì§€ ì¦ëª….
    2.  **[2ìˆœìœ„-ì „ëµ ìœµí•©]:** ê·¸ ë‹¤ìŒ, ì—¬ê¸°ì— **(2)ë²ˆ ì „ëµ**ì„ ì–´ë–»ê²Œ ë…¹ì—¬ë‚´ì–´, ì´ ê²½í—˜ì„ **ë‹¤ë¥¸ ê°€ê²Œì—ì„œëŠ” í•  ìˆ˜ ì—†ëŠ” ìš°ë¦¬ ê°€ê²Œë§Œì˜ íŠ¹ë³„í•œ ê²½í—˜**ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ”ì§€ ì¦ëª….

---

**(ì‚¬ì¥ë‹˜ê»˜ ê³ ê° ì¤‘ì‹¬ì  ì‚¬ê³ ì˜ ì¤‘ìš”ì„±ì„ ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°í•˜ë©°, ì§„ì‹¬ ì–´ë¦° ì‘ì›ì˜ ë©”ì‹œì§€ë¡œ ë§ˆë¬´ë¦¬)**
"""


        # [ìˆ˜ì •] ìµœì¢… ë¦¬í¬íŠ¸ ì–‘ì‹ ë³€ê²½
        # LangChain Agentê°€ LLMì˜ ì‘ë‹µì„ ìµœì¢…ì ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ëŠ” ë¶€ë¶„ì´ë¯€ë¡œ,
        # ì—¬ê¸°ì„œëŠ” ë°ì´í„° ë¶„ì„ ê²°ê³¼ë§Œ ëª…í™•íˆ ì œì‹œí•˜ê³  LLMì—ê²Œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ì—¬
        # Agentê°€ LLMì„ í˜¸ì¶œí•˜ê³  ê·¸ ì‘ë‹µì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ë¶™ì´ë„ë¡ í•©ë‹ˆë‹¤.

        final_report = f"""
======================================================================
ğŸ¤– AI ë¹„ë°€ìƒë‹´ì‚¬ - '{store_id}' ê°€ë§¹ì  ë§ì¶¤ ì „ëµ ë¦¬í¬íŠ¸
======================================================================

1. ìš°ë¦¬ ê°€ê²Œ ì£¼ìš” ê³ ê° íŠ¹ì§• ë¶„ì„ (í˜ë¥´ì†Œë‚˜ ê¸°ë°˜)

{main_personas_details_str}

2. ìš°ë¦¬ ê°€ê²Œ í•µì‹¬ ì„±ê³µ ì „ëµ

ìš°ë¦¬ ê°€ê²Œê°€ ì†í•œ '{store_commercial_area}' ìƒê¶Œì˜ ì¹´í˜ ì—…ì¢…ì€ '{core_strategy}' ì „ëµì´ ì„±ê³µì˜ ì—´ì‡ ì…ë‹ˆë‹¤.

3. AIê°€ ì œì•ˆí•˜ëŠ” ë§ì¶¤ ë§ˆì¼€íŒ… ì „ëµ

(AIê°€ ì•„ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.)
{prompt_for_gemini}
"""
        return final_report

    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return f"""ğŸš¨ ì¹´í˜ ë§ˆì¼€íŒ… ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ìƒì„¸ ì •ë³´:**
- ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}
- ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}
- ê°€ë§¹ì  ID: {store_id}

**í•´ê²° ë°©ë²•:**
1. ê°€ë§¹ì  IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
2. ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ê°€ë§¹ì  ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
3. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”

**ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:**
{error_details}"""
# =============================================================================
# ëª¨ë¸ 2: ì¬ë°©ë¬¸ìœ¨ 30% ì´í•˜ ê°€ë§¹ì  ì›ì¸ ì§„ë‹¨ ë° A/B ì „ëµ ì œì•ˆ
# =============================================================================

@tool
def revisit_rate_analysis_tool(store_id: str, df_all_join: pd.DataFrame, df_prompt_dna: pd.DataFrame) -> str:
    """
    ì¬ë°©ë¬¸ìœ¨ì´ 30% ì´í•˜ë¡œ ë‚®ì€ ê°€ë§¹ì ì˜ ê·¼ë³¸ì ì¸ ì›ì¸ì„ 3ê°€ì§€ í•µì‹¬ ë™ì¸(ê°€ê²©, ê³ ê°ì¸µ, ì±„ë„)ìœ¼ë¡œ 
    ê²½ìŸ ê·¸ë£¹ê³¼ ë¹„êµ ë¶„ì„í•˜ê³ , ì¬ë°©ë¬¸ìœ¨ì„ ë†’ì´ê¸° ìœ„í•œ A/B ì „ëµì„ ì œì•ˆí•˜ëŠ” ë„êµ¬.
    'ì¬ë°©ë¬¸', 'ë‹¨ê³¨' ë¬¸ì œì— íŠ¹í™”ë˜ì–´ ìˆë‹¤.
    
    Args:
        store_id: ë¶„ì„í•  ê°€ë§¹ì  ID
        df_all_join: ì „ì²´ JOIN ë°ì´í„°
        df_prompt_dna: AIìƒë‹´ì‚¬ í•µì‹¬ì „ëµ í”„ë¡¬í”„íŠ¸ ë°ì´í„°
    
    Returns:
        ì¬ë°©ë¬¸ìœ¨ ë¶„ì„ ë° ê°œì„  ì „ëµ ë¦¬í¬íŠ¸
    """
    try:
        # ì ìˆ˜ ì»¬ëŸ¼ ìƒì„± (í•„ìš”í•œ ê²½ìš°)
        score_cols = ['MCT_OPE_MS_CN', 'RC_M1_TO_UE_CT', 'RC_M1_SAA', 'RC_M1_AV_NP_AT']
        for col in score_cols:
            if col in df_all_join.columns and f'{col}_SCORE' not in df_all_join.columns:
                df_all_join[f'{col}_SCORE'] = df_all_join[col].apply(get_score_from_raw)
        
        target_store_all_months = df_all_join[df_all_join['ENCODED_MCT'] == store_id]
        if target_store_all_months.empty:
            return f"ğŸš¨ ë¶„ì„ ë¶ˆê°€: ë°ì´í„°ì…‹ì—ì„œ '{store_id}' ê°€ë§¹ì  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        target_store = target_store_all_months.sort_values(by='TA_YM', ascending=False).iloc[0]

        # ì¬ë°©ë¬¸ìœ¨ ê³„ì‚° (ì›”ë³„ í‰ê· )
        target_revisit_rate_series = target_store_all_months['MCT_UE_CLN_REU_RAT'].dropna()
        target_revisit_rate = 0.0 if target_revisit_rate_series.empty else target_revisit_rate_series.mean()

        if target_revisit_rate >= 30:
            latest_month = target_store.get('TA_YM', 'ìµœì‹ ')
            return f"âœ… ë¶„ì„ ê²°ê³¼: ì›” í‰ê·  ì¬ë°©ë¬¸ìœ¨ì´ {target_revisit_rate:.1f}%ë¡œ ì–‘í˜¸í•©ë‹ˆë‹¤. (ìµœì‹ ì›”: {latest_month})"

        industry, commercial_area = target_store['ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜'], target_store['HPSN_MCT_BZN_CD_NM']
        area_name = commercial_area if pd.notna(commercial_area) else "ë¹„ìƒê¶Œ"
        
        # ê²½ìŸ ê·¸ë£¹ ì„¤ì •
        peer_group_filter = (df_all_join['ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜'] == industry) & (df_all_join['ENCODED_MCT'] != store_id)
        if pd.isna(commercial_area):
            peer_group = df_all_join[peer_group_filter & (df_all_join['HPSN_MCT_BZN_CD_NM'].isna())]
        else:
            peer_group = df_all_join[peer_group_filter & (df_all_join['HPSN_MCT_BZN_CD_NM'] == commercial_area)]

        if len(peer_group) < 3:
            return f"ğŸŸ¡ ë¶„ì„ ë³´ë¥˜: ë¹„êµ ë¶„ì„ì„ ìœ„í•œ ê²½ìŸ ê·¸ë£¹ì´ ë¶€ì¡±í•©ë‹ˆë‹¤."
            
        revisit_threshold = peer_group['MCT_UE_CLN_REU_RAT'].quantile(0.5)
        successful_peers = peer_group[peer_group['MCT_UE_CLN_REU_RAT'] >= revisit_threshold]
        if successful_peers.empty:
            return f"ğŸŸ¡ ë¶„ì„ ë³´ë¥˜: ì„±ê³µ ê·¸ë£¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # 3ëŒ€ ì§€í‘œ ê³„ì‚°
        def get_series_mean(series):
            series_cleaned = series.dropna()
            return 0.0 if series_cleaned.empty else series_cleaned.mean()

        def get_group_mean(df, group_col, value_col):
            if df.empty or value_col not in df.columns:
                return 0.0
            group_means = df.groupby(group_col)[value_col].mean()
            final_mean = group_means.mean()
            return 0.0 if pd.isna(final_mean) else final_mean

        # ë‚´ ê°€ê²Œì˜ ì „ì²´ ê¸°ê°„ í‰ê·  ê³„ì‚°
        target_price_score_avg = get_series_mean(target_store_all_months['RC_M1_AV_NP_AT_SCORE'])
        target_resident_ratio_avg = get_series_mean(target_store_all_months['RC_M1_SHC_RSD_UE_CLN_RAT'])
        target_delivery_ratio_avg = get_series_mean(target_store_all_months['DLV_SAA_RAT'])

        # ì„±ê³µ ê·¸ë£¹ì˜ ê°€ê²Œë³„ í‰ê·  ê³„ì‚° í›„ -> ì „ì²´ í‰ê· 
        peer_price_score_avg = get_group_mean(successful_peers, 'ENCODED_MCT', 'RC_M1_AV_NP_AT_SCORE')
        peer_resident_ratio_avg = get_group_mean(successful_peers, 'ENCODED_MCT', 'RC_M1_SHC_RSD_UE_CLN_RAT')
        peer_delivery_avg = get_group_mean(successful_peers, 'ENCODED_MCT', 'DLV_SAA_RAT')
        
        # ë°°ë‹¬ ë¯¸ìš´ì˜ ê°€ê²Œ ì²˜ë¦¬ ë¡œì§
        is_delivery_not_operated = (target_delivery_ratio_avg == 0.0)
        
        delivery_target_for_analysis = target_delivery_ratio_avg
        delivery_peer_for_analysis = peer_delivery_avg

        if is_delivery_not_operated:
            delivery_peer_for_analysis = 0.0
            delivery_target_for_analysis = 0.0

        analysis_results = {
            'price_competitiveness': {'target': target_price_score_avg, 'peer_avg': peer_price_score_avg},
            'audience_alignment': {'target': target_resident_ratio_avg, 'peer_avg': peer_resident_ratio_avg},
            'channel_expansion': {'target': delivery_target_for_analysis, 'peer_avg': delivery_peer_for_analysis}
        }
        
        for key in analysis_results:
            analysis_results[key]['gap'] = analysis_results[key].get('target', np.nan) - analysis_results[key].get('peer_avg', np.nan)
        
        # í˜ë¥´ì†Œë‚˜ ì§„ë‹¨
        gaps = {k: v['gap'] for k, v in analysis_results.items() if 'gap' in v and pd.notna(v['gap'])}
        if not gaps:
            persona = "ë¶„ì„ ë¶ˆê°€"
        else:
            op_tenure_score = target_store.get('MCT_OPE_MS_CN_SCORE', 6)
            new_ratio = target_store.get('MCT_UE_CLN_NEW_RAT', 0)
            
            if op_tenure_score <= 2 and new_ratio > 60:
                persona = "ì²«ì¸ìƒë§Œ ì¢‹ì€ ì‹ ê·œ ë§¤ì¥"
            elif gaps.get('price_competitiveness', 0) < -1:
                persona = "ì¬ë°©ë¬¸í•˜ê¸°ì—” ë¶€ë‹´ìŠ¤ëŸ¬ìš´ ê°€ê²©"
            elif gaps.get('audience_alignment', 0) < -15:
                persona = "ë™ë„¤ ì£¼ë¯¼ì„ ì‚¬ë¡œì¡ì§€ ëª»í•˜ëŠ” ë§¤ì¥"
            elif gaps.get('channel_expansion', 0) < -20:
                persona = "ë°°ë‹¬ ì±„ë„ ë¶€ì¬"
            else:
                persona = "ì´ì²´ì  ë§ˆì¼€íŒ… ë¶€ì¬"

        # ì „ëµ ë°ì´í„° ì¡°íšŒ
        strategy_row = df_prompt_dna[(df_prompt_dna['ì—…ì¢…'] == industry) & (df_prompt_dna['ìƒê¶Œ'] == area_name)]
        if not strategy_row.empty:
            key_factor = strategy_row.iloc[0]['í•µì‹¬ì„±ê³µë³€ìˆ˜(DNA)']
            key_strategy = strategy_row.iloc[0]['í•µì‹¬ê²½ì˜ì „ëµ']
        else:
            key_factor = "ë°ì´í„° ì—†ìŒ"
            key_strategy = "ì¼ë°˜ì ì¸ ê°œì„  ì „ëµ í•„ìš”"

        # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        final_report = f"""
======================================================================
      ğŸ©º AI ì¬ë°©ë¬¸ìœ¨ ì§„ë‹¨ - '{store_id}' ê°€ë§¹ì  ë¶„ì„ ë¦¬í¬íŠ¸
======================================================================

### ğŸ“Š í˜„ì¬ ìƒí™© ì§„ë‹¨

* **ì—…ì¢…/ìƒê¶Œ:** {industry} / {area_name}
* **í˜„ì¬ ì¬ë°©ë¬¸ìœ¨:** {target_revisit_rate:.1f}% (ì›” í‰ê· )
* **AI ì§„ë‹¨ í˜ë¥´ì†Œë‚˜:** {persona}

### ğŸ” 3ëŒ€ í•µì‹¬ ë™ì¸ ë¶„ì„

**â‘  ê°€ê²© ê²½ìŸë ¥ (ê°ë‹¨ê°€)**
- ë‚´ ê°€ê²Œ: {target_price_score_avg:.2f}ì 
- ì„±ê³µ ê·¸ë£¹ í‰ê· : {peer_price_score_avg:.2f}ì 
- ê²©ì°¨: {analysis_results['price_competitiveness']['gap']:.2f}ì 

**â‘¡ í•µì‹¬ ê³ ê°ì¸µ (ê±°ì£¼ì ë¹„ìœ¨)**
- ë‚´ ê°€ê²Œ: {target_resident_ratio_avg:.1f}%
- ì„±ê³µ ê·¸ë£¹ í‰ê· : {peer_resident_ratio_avg:.1f}%
- ê²©ì°¨: {analysis_results['audience_alignment']['gap']:.1f}%p

**â‘¢ ì±„ë„ í™•ì¥ì„± (ë°°ë‹¬ ë¹„ìœ¨)**
- ë‚´ ê°€ê²Œ: {target_delivery_ratio_avg:.1f}%
- ì„±ê³µ ê·¸ë£¹ í‰ê· : {peer_delivery_avg:.1f}%
- ê²©ì°¨: {analysis_results['channel_expansion']['gap']:.1f}%p

### ğŸš€ ê°œì„  ì „ëµ ì œì•ˆ

**í•µì‹¬ ì„±ê³µ ë³€ìˆ˜:** {key_factor}
**í•µì‹¬ ê²½ì˜ ì „ëµ:** {key_strategy}

**A/B ì „ëµ ì˜µì…˜:**

**ì „ëµ A (ê°•ì  ê°•í™”/ì°¨ë³„í™”):**
- í˜„ì¬ ì˜í•˜ê³  ìˆëŠ” ë¶€ë¶„ì„ ë”ìš± ê°•í™”
- ì‹œì¥ì˜ ê·œì¹™ì„ ë”°ë¥´ëŠ” ëŒ€ì‹  ìƒˆë¡œìš´ ê·œì¹™ì„ ë§Œë“œëŠ” ì „ëµ

**ì „ëµ B (ì•½ì  ë³´ì™„/ë™ê¸°í™”):**
- ì„±ê³µ ê·¸ë£¹ì˜ ì „ëµì„ ë²¤ì¹˜ë§ˆí‚¹
- ì•ˆì •ì ì¸ ì„±ê³µ ë°©ì •ì‹ì„ ë”°ë¥´ëŠ” ì „ëµ

### ğŸ’¡ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ í”Œëœ

1. **ë‹¨ê¸° ê¸´ê¸‰ ì²˜ë°© (1-2ì£¼)**
   - {persona} ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜

2. **ì¤‘ì¥ê¸° í•µì‹¬ ì „ëµ (1-3ê°œì›”)**
   - {key_strategy} ê¸°ë°˜ì˜ ì²´ê³„ì ì¸ ê°œì„  ê³„íš

3. **ì„±ê³¼ ì¸¡ì • ë° ìµœì í™”**
   - ì¬ë°©ë¬¸ìœ¨ ë³€í™” ëª¨ë‹ˆí„°ë§ ë° ì „ëµ ì¡°ì •

"""
        return final_report

    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return f"""ğŸš¨ ì¬ë°©ë¬¸ìœ¨ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ìƒì„¸ ì •ë³´:**
- ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}
- ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}
- ê°€ë§¹ì  ID: {store_id}

**í•´ê²° ë°©ë²•:**
1. ê°€ë§¹ì  IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
2. ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ê°€ë§¹ì  ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
3. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”

**ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:**
{error_details}"""

# =============================================================================
# ëª¨ë¸ 3: ìš”ì‹ì—…ì¢… ê°€ë§¹ì ì˜ ì „ë°©ìœ„ ê°•ì /ì•½ì  ë¶„ì„ ë° ì†”ë£¨ì…˜ ì œì•ˆ
# =============================================================================

def apply_emphasis(score):
    """ì ìˆ˜ë¥¼ 0-100 ë²”ìœ„ì—ì„œ ì–‘ ê·¹ë‹¨ìœ¼ë¡œ ìŠ¤íŠ¸ë ˆì¹­í•˜ì—¬ ì°¨ì´ë¥¼ ëª…í™•í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤."""
    x = (score - 50) / 50
    y = np.sign(x) * (abs(x) ** 0.7)
    return max(0, min(100, (y * 50) + 50))

def get_percentile_score(store_value, benchmark_series, higher_is_better=True):
    """ê²½ìŸ ê·¸ë£¹ ë‚´ ë°±ë¶„ìœ„ ìˆœìœ„ë¥¼ 0-100ì  ì²™ë„ì˜ 'ê±´ê°• ì ìˆ˜'ë¡œ ë³€í™˜í•˜ê³  ê°€ì¤‘ì¹˜ë¥¼ ì ìš©"""
    if pd.isna(store_value) or benchmark_series.empty:
        return 50
    combined = pd.concat([benchmark_series, pd.Series([store_value])])
    percentile = combined.rank(pct=True, na_option='bottom').iloc[-1]
    raw_score = percentile * 100 if higher_is_better else (1 - percentile) * 100
    return apply_emphasis(raw_score)

def parse_segment(segment_name):
    """ì„¸ê·¸ë¨¼íŠ¸ ì´ë¦„ì„ íŒŒì‹±í•˜ì—¬ ì„±ë³„ê³¼ ì—°ë ¹ ì •ë³´ ì¶”ì¶œ"""
    parts = segment_name.replace('M12_', '').replace('_RAT', '').split('_')
    return {'name': segment_name, 'gender': parts[0], 'age': parts[1]}

def get_age_tier(age_str):
    """ì—°ë ¹ëŒ€ë¥¼ ìˆ«ìë¡œ ë³€í™˜"""
    tiers = {'1020': 1, '30': 2, '40': 3, '50': 4, '60': 5}
    return tiers.get(age_str, 0)

def calculate_advanced_match_score(area_top2_names, store_top2_names):
    """'Top 2 ë¹„êµ ë° ìœ ì‚¬ë„ ë³´ë„ˆìŠ¤' ë¡œì§ìœ¼ë¡œ ì í•©ë„ ì ìˆ˜ ê³„ì‚°"""
    intersection_count = len(set(area_top2_names) & set(store_top2_names))
    
    base_score = 0
    if intersection_count == 2:
        base_score = 85
    elif intersection_count == 1:
        base_score = 45
    else:
        base_score = 5

    bonus_score = 0
    non_matching_area = [parse_segment(s) for s in set(area_top2_names) - set(store_top2_names)]
    non_matching_store = [parse_segment(s) for s in set(store_top2_names) - set(store_top2_names)]

    for s_seg in non_matching_store:
        for a_seg in non_matching_area:
            if s_seg['age'] == a_seg['age']:
                bonus_score = max(bonus_score, 10)
            if s_seg['gender'] == a_seg['gender'] and abs(get_age_tier(s_seg['age']) - get_age_tier(a_seg['age'])) == 1:
                bonus_score = max(bonus_score, 5)
    
    return max(0, min(100, base_score + bonus_score))

@tool # ì—¬ê¸° ìˆ˜ì •í•´ì•¼í•¨(ê°€ë§¹ì  ëª… í˜•ì‹ ì˜¤ë¥˜)
def search_merchant_tool(merchant_name: str, df_all_join: pd.DataFrame) -> str:
    """
    ê°€ë§¹ì  ì´ë¦„ì„ ì…ë ¥ë°›ì•„, í•´ë‹¹ ê°€ë§¹ì ì˜ ê¸°ë³¸ ì •ë³´(ì—…ì¢…, ì£¼ì†Œ, ê°œì„¤ì¼ ë“±)ë¥¼ 
    ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬.
    ì‚¬ìš©ìê°€ ê°€ê²Œì˜ ê¸°ë³¸ ì •ë³´ë§Œ ìš”ì²­í•  ë•Œ ì‚¬ìš©ëœë‹¤.
    
    Args:
        merchant_name: ê²€ìƒ‰í•  ê°€ë§¹ì ëª… (ë¶€ë¶„ ì¼ì¹˜ ì§€ì›)
        df_all_join: ì „ì²´ JOIN ë°ì´í„°
    
    Returns:
        ê°€ë§¹ì  ê²€ìƒ‰ ê²°ê³¼ ë¦¬í¬íŠ¸
    """
    try:
        # ê°€ë§¹ì ëª…ìœ¼ë¡œ ê²€ìƒ‰ (exact match)
        result = df_all_join[df_all_join['ê°€ë§¹ì ëª…'].astype(str).str.replace('*', '') == merchant_name.replace('*', '')]
        
        if len(result) == 0:
            return f"""
ğŸš¨ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ

'{merchant_name}'ì— í•´ë‹¹í•˜ëŠ” ê°€ë§¹ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ğŸ’¡ ê²€ìƒ‰ íŒ:
- ì •í™•í•œ ê°€ë§¹ì ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”
- '*' ê¸°í˜¸ëŠ” ìë™ìœ¼ë¡œ ì œê±°ë©ë‹ˆë‹¤
- ëŒ€ì†Œë¬¸ìëŠ” êµ¬ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤

ì¡°íšŒ ê°€ëŠ¥í•œ ì˜ˆì‹œ: ë™ëŒ€*, ìœ ìœ *, ë˜¥íŒŒ*, ë³¸ì£½*, ë³¸*, ì›ì¡°*, í¬ë§*, í˜ì´*, Hì»¤*, ì¼€í‚¤*
"""
        
        # ìµœì‹  ë°ì´í„° ì„ íƒ (TA_YM ê¸°ì¤€)
        latest_result = result.sort_values(by='TA_YM', ascending=False).iloc[0]
        
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        store_name = latest_result.get('ê°€ë§¹ì ëª…', 'ì •ë³´ ì—†ìŒ')
        industry = latest_result.get('ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜', 'ì •ë³´ ì—†ìŒ')
        address = latest_result.get('HPSN_MCT_BZN_CD_NM', 'ì •ë³´ ì—†ìŒ')
        commercial_area = latest_result.get('HPSN_MCT_BZN_CD_NM', 'ë¹„ìƒê¶Œ')
        
        # ë§¤ì¶œ ê´€ë ¨ ì •ë³´
        revenue_level = latest_result.get('RC_M1_SAA', 'ì •ë³´ ì—†ìŒ')
        customer_count_level = latest_result.get('RC_M1_UE_CUS_CN', 'ì •ë³´ ì—†ìŒ')
        avg_amount_level = latest_result.get('RC_M1_AV_NP_AT', 'ì •ë³´ ì—†ìŒ')
        
        # ê³ ê° ë¹„ìœ¨ ì •ë³´
        new_customer_ratio = latest_result.get('MCT_UE_CLN_NEW_RAT', 0)
        revisit_ratio = latest_result.get('MCT_UE_CLN_REU_RAT', 0)
        resident_ratio = latest_result.get('RC_M1_SHC_RSD_UE_CLN_RAT', 0)
        delivery_ratio = latest_result.get('DLV_SAA_RAT', 0)
        
        # ìš´ì˜ ê¸°ê°„
        operation_period = latest_result.get('MCT_OPE_MS_CN', 'ì •ë³´ ì—†ìŒ')
        
        # ìµœì‹  ì›”
        latest_month = latest_result.get('TA_YM', 'ì •ë³´ ì—†ìŒ')
        
        # ê²€ìƒ‰ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
        report = f"""
======================================================================
      ğŸª ê°€ë§¹ì  ê¸°ë³¸ ì •ë³´ - '{store_name}' ê²€ìƒ‰ ê²°ê³¼
======================================================================

### ğŸ“‹ ê¸°ë³¸ ì •ë³´
- **ê°€ë§¹ì ëª…:** {store_name}
- **ì—…ì¢…:** {industry}
- **ìƒê¶Œ:** {commercial_area if pd.notna(commercial_area) else 'ë¹„ìƒê¶Œ'}
- **ìš´ì˜ ê¸°ê°„:** {operation_period}
- **ìµœì‹  ë°ì´í„°:** {latest_month}

### ğŸ’° ë§¤ì¶œ í˜„í™© (ìµœì‹ ì›” ê¸°ì¤€)
- **ë§¤ì¶œ ìˆ˜ì¤€:** {revenue_level}
- **ë°©ë¬¸ ê³ ê° ìˆ˜:** {customer_count_level}
- **ê°ë‹¨ê°€ ìˆ˜ì¤€:** {avg_amount_level}

### ğŸ‘¥ ê³ ê° ë¶„ì„ (ìµœì‹ ì›” ê¸°ì¤€)
- **ì‹ ê·œ ê³ ê° ë¹„ìœ¨:** {new_customer_ratio:.1f}%
- **ì¬ë°©ë¬¸ ê³ ê° ë¹„ìœ¨:** {revisit_ratio:.1f}%
- **ê±°ì£¼ ê³ ê° ë¹„ìœ¨:** {resident_ratio:.1f}%
- **ë°°ë‹¬ ë§¤ì¶œ ë¹„ìœ¨:** {delivery_ratio:.1f}%

### ğŸ” ì¶”ê°€ ë¶„ì„ ê°€ëŠ¥
ì´ ê°€ë§¹ì ì— ëŒ€í•´ ë” ìì„¸í•œ ë¶„ì„ì„ ì›í•˜ì‹œë©´ ë‹¤ìŒì„ ìš”ì²­í•´ì£¼ì„¸ìš”:
- **ë§ˆì¼€íŒ… ì „ëµ ë¶„ì„** (ì¹´í˜ ì—…ì¢…ì¸ ê²½ìš°)
- **ì¬ë°©ë¬¸ìœ¨ ê°œì„  ë°©ì•ˆ** (ì¬ë°©ë¬¸ìœ¨ì´ ë‚®ì€ ê²½ìš°)
- **ì „ì²´ì ì¸ ê°•ì /ì•½ì  ì§„ë‹¨**

======================================================================
"""
        
        return report
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return f"""ğŸš¨ ê°€ë§¹ì  ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ìƒì„¸ ì •ë³´:**
- ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}
- ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}
- ê²€ìƒ‰ì–´: {merchant_name}

**í•´ê²° ë°©ë²•:**
1. ê°€ë§¹ì ëª…ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
2. ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ê°€ë§¹ì  ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
3. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”

**ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:**
{error_details}"""

@tool
def store_strength_weakness_tool(store_id: str, df_all_join: pd.DataFrame) -> str:
    """
    ìš”ì‹ì—…ì¢… ê°€ë§¹ì ì˜ ì „ë°˜ì ì¸ ê±´ê°• ìƒíƒœë¥¼ ë‹¤ê°ë„ë¡œ ë¶„ì„í•˜ì—¬, 
    ê²½ìŸ ê·¸ë£¹ ëŒ€ë¹„ ëª…í™•í•œ ê°•ì ê³¼ ì•½ì ì„ ì§„ë‹¨í•˜ê³ , 
    ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì„  ì†”ë£¨ì…˜ì„ ì œì•ˆí•˜ëŠ” ë„êµ¬.
    ê°€ê²Œì˜ 'ë¬¸ì œì ', 'ê°€ì¥ í° ë¬¸ì œì ' ì— ëŒ€í•œ í¬ê´„ì ì¸ ì§„ë‹¨ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©ëœë‹¤.
    
    Args:
        store_id: ë¶„ì„í•  ê°€ë§¹ì  ID
        df_all_join: ì „ì²´ JOIN ë°ì´í„°
    
    Returns:
        ê°•ì /ì•½ì  ë¶„ì„ ë° ê°œì„  ì†”ë£¨ì…˜ ë¦¬í¬íŠ¸
    """
    try:
        store_df = df_all_join[df_all_join['ENCODED_MCT'] == store_id].tail(12)
        if store_df.empty:
            return f"ğŸš¨ ë¶„ì„ ë¶ˆê°€: '{store_id}' ê°€ë§¹ì ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        category, commercial_area = store_df[['ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜', 'HPSN_MCT_BZN_CD_NM']].iloc[0]
        
        if pd.notna(commercial_area):
            benchmark_type = "ë™ì¼ ìƒê¶Œ ë‚´ ë™ì¢…ì—…ê³„"
            benchmark_df = df_all_join[(df_all_join['ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜'] == category) & (df_all_join['HPSN_MCT_BZN_CD_NM'] == commercial_area)]
        else:
            benchmark_type = "ë¹„ìƒê¶Œ ì§€ì—­ì˜ ë™ì¢…ì—…ê³„"
            benchmark_df = df_all_join[(df_all_join['ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜'] == category) & (df_all_join['HPSN_MCT_BZN_CD_NM'].isna())]
        
        # ë¶„ì„í•  ì§€í‘œë“¤ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •)
        metrics_to_analyze = [
            {'name': 'ë§¤ì¶œ ê·œëª¨', 'col': 'RC_M1_SAA', 'type': 'tier', 'higher_is_better': False},
            {'name': 'ë°©ë¬¸ ê³ ê° ìˆ˜', 'col': 'RC_M1_UE_CUS_CN', 'type': 'tier', 'higher_is_better': False},
            {'name': 'ê³ ê°ë‹¹ ì§€ì¶œì•¡(ê°ë‹¨ê°€)', 'col': 'RC_M1_AV_NP_AT', 'type': 'tier', 'higher_is_better': False},
            {'name': 'ì—…ì¢… í‰ê·  ëŒ€ë¹„ ë§¤ì¶œ', 'col': 'M1_SME_RY_SAA_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ì‹ ê·œ ê³ ê° ë¹„ìœ¨', 'col': 'MCT_UE_CLN_NEW_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ì¬ë°©ë¬¸ ê³ ê° ë¹„ìœ¨', 'col': 'MCT_UE_CLN_REU_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ë°°ë‹¬ ë§¤ì¶œ ë¹„ìœ¨', 'col': 'DLV_SAA_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ê±°ì£¼ ê³ ê° ë¹„ìœ¨', 'col': 'RC_M1_SHC_RSD_UE_CLN_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ì§ì¥ì¸ ê³ ê° ë¹„ìœ¨', 'col': 'RC_M1_SHC_WP_UE_CLN_RAT', 'type': 'ratio', 'higher_is_better': True},
            {'name': 'ìœ ë™ì¸êµ¬ ê³ ê° ë¹„ìœ¨', 'col': 'RC_M1_SHC_FLP_UE_CLN_RAT', 'type': 'ratio', 'higher_is_better': True},
        ]

        # ë°°ë‹¬ ë°ì´í„° í™•ì¸
        has_delivery_data = store_df['DLV_SAA_RAT'].sum() > 0
        if not has_delivery_data:
            metrics_to_analyze = [m for m in metrics_to_analyze if m['name'] != 'ë°°ë‹¬ ë§¤ì¶œ ë¹„ìœ¨']

        all_scores = []
        for metric in metrics_to_analyze:
            if metric['type'] == 'tier':
                # tier íƒ€ì…ì€ í…ìŠ¤íŠ¸ ê°’ì´ë¯€ë¡œ ìˆ«ìë¡œ ë³€í™˜
                store_val = get_score_from_raw(store_df[metric['col']].iloc[-1]) if not store_df.empty else np.nan
                benchmark_series = benchmark_df[metric['col']].apply(get_score_from_raw)
            else:
                # ratio íƒ€ì…ì€ ìˆ«ì ê°’
                store_val = store_df[metric['col']].mean()
                benchmark_series = benchmark_df.groupby('ENCODED_MCT')[metric['col']].mean()
            
            score = get_percentile_score(store_val, benchmark_series, metric['higher_is_better'])
            
            store_display, benchmark_display = "", ""
            if metric['type'] == 'ratio':
                store_display = f"{store_val:.1%}"
                benchmark_display = f"{benchmark_series.mean():.1%}"
            elif metric['type'] == 'tier':
                store_display = store_df[metric['col']].iloc[-1] if not store_df.empty else "N/A"
                benchmark_display = benchmark_df[metric['col']].mode()[0] if not benchmark_df.empty and not benchmark_df[metric['col']].mode().empty else "N/A"

            all_scores.append({
                'metric': metric['name'], 
                'score': f"{score:.1f}ì ",
                'store_value_display': store_display,
                'benchmark_value_display': benchmark_display
            })

        # ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„
        demo_cols = [col for col in df_all_join.columns if ('MAL' in col or 'FME' in col) and 'RAT' in col]
        area_detailed_profile = benchmark_df[demo_cols].mean()
        store_detailed_profile = store_df[demo_cols].mean()
        area_top2, store_top2 = area_detailed_profile.nlargest(2), store_detailed_profile.nlargest(2)

        match_score = calculate_advanced_match_score(area_top2.index.tolist(), store_top2.index.tolist())
        all_scores.append({
            'metric': 'ìƒê¶Œ-ê³ ê° ì í•©ë„', 
            'score': f"{match_score:.1f}ì ",
            'store_value_display': f"Top 2: {[n.replace('M12_','').replace('_RAT','') for n in store_top2.index.tolist()]}",
            'benchmark_value_display': f"Top 2: {[n.replace('M12_','').replace('_RAT','') for n in area_top2.index.tolist()]}"
        })
        
        # ê°•ì ê³¼ ì•½ì  ë¶„ë¥˜
        strengths = [r for r in all_scores if float(r['score'].replace('ì ','')) > 80]
        weaknesses = [r for r in all_scores if (r['metric'] != 'ìƒê¶Œ-ê³ ê° ì í•©ë„' and float(r['score'].replace('ì ','')) < 20) or \
                                           (r['metric'] == 'ìƒê¶Œ-ê³ ê° ì í•©ë„' and float(r['score'].replace('ì ','')) < 40)]
        
        if not weaknesses and all_scores:
            weakest_link = min(all_scores, key=lambda x: float(x['score'].replace('ì ','')))
            weaknesses.append(weakest_link)
            
        # ì •ë ¬
        sorted_strengths = sorted(strengths, key=lambda x: float(x['score'].split('ì ')[0]), reverse=True)
        sorted_weaknesses = sorted(weaknesses, key=lambda x: float(x['score'].split('ì ')[0]))

        # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        final_report = f"""
======================================================================
      ğŸ“Š AI ì „ë°©ìœ„ ì§„ë‹¨ - '{store_id}' ê°€ë§¹ì  ê±´ê°•ë„ ë¶„ì„ ë¦¬í¬íŠ¸
======================================================================

### ğŸ“ˆ ë¶„ì„ ê°œìš”

* **ë¶„ì„ ëŒ€ìƒ:** {store_id}
* **ë¶„ì„ ê¸°ì¤€:** {benchmark_type} (ìµœê·¼ 12ê°œì›” ë°ì´í„°)
* **ì—…ì¢…/ìƒê¶Œ:** {category} / {commercial_area if pd.notna(commercial_area) else 'ë¹„ìƒê¶Œ'}

### âœ… ê°•ì  ìš”ì•½ (Top 3)

"""
        
        if sorted_strengths:
            for i, s in enumerate(sorted_strengths[:3], 1):
                score = float(s['score'].replace('ì ',''))
                interpretation = f"ê²½ìŸì  ëŒ€ë¹„ ìƒìœ„ {100-score:.0f}% ìˆ˜ì¤€ì˜ ë›°ì–´ë‚œ ì„±ê³¼"
                final_report += f"""
**{i}. {s['metric']} (ê±´ê°• ì ìˆ˜: {s['score']})**
- í•´ì„: {interpretation}
- ë°ì´í„°: ìš°ë¦¬ ê°€ê²Œ({s['store_value_display']}) vs ê²½ìŸì ({s['benchmark_value_display']})
"""
        else:
            final_report += "íŠ¹ë³„í•œ ê°•ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"

        final_report += """
### âŒ ì•½ì  ìš”ì•½ (Top 3)

"""
        
        if sorted_weaknesses:
            for i, w in enumerate(sorted_weaknesses[:3], 1):
                score = float(w['score'].replace('ì ',''))
                interpretation = f"ê²½ìŸì  ëŒ€ë¹„ í•˜ìœ„ {score:.0f}% ìˆ˜ì¤€ìœ¼ë¡œ ê°œì„ ì´ í•„ìš”í•¨" if score < 40 else "ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•˜ë‚˜ ìƒëŒ€ì ìœ¼ë¡œ ì•„ì‰¬ìš´ ì§€í‘œ"
                final_report += f"""
**{i}. {w['metric']} (ê±´ê°• ì ìˆ˜: {w['score']})**
- í•´ì„: {interpretation}
- ë°ì´í„°: ìš°ë¦¬ ê°€ê²Œ({w['store_value_display']}) vs ê²½ìŸì ({w['benchmark_value_display']})
"""
        else:
            final_report += "íŠ¹ë³„í•œ ì•½ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"

        final_report += """
### ğŸš€ ì¢…í•© ì§„ë‹¨ ë° ê°œì„  ì†”ë£¨ì…˜

**í•µì‹¬ ë¬¸ì œ ì§„ë‹¨:**
"""
        
        if sorted_weaknesses:
            main_weakness = sorted_weaknesses[0]
            final_report += f"- ê°€ì¥ ì‹œê¸‰í•œ ê°œì„  ê³¼ì œ: {main_weakness['metric']}\n"
            final_report += f"- í˜„ì¬ ìˆ˜ì¤€: {main_weakness['store_value_display']}\n"
            final_report += f"- ëª©í‘œ ìˆ˜ì¤€: {main_weakness['benchmark_value_display']}\n"
        else:
            final_report += "- ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤.\n"

        final_report += """
**ë§ˆì¼€íŒ… ì œì•ˆ:**

1. **ê°•ì  í™œìš© ì „ëµ**
   - í˜„ì¬ ì˜í•˜ê³  ìˆëŠ” ë¶€ë¶„ì„ ë”ìš± ê°•í™”í•˜ì—¬ ê²½ìŸ ìš°ìœ„ í™•ë³´
   - ê°•ì ì„ ë§ˆì¼€íŒ… í¬ì¸íŠ¸ë¡œ í™œìš©í•œ ì°¨ë³„í™” ì „ëµ

2. **ì•½ì  ë³´ì™„ ì „ëµ**
   - ê°€ì¥ ì•½í•œ ë¶€ë¶„ë¶€í„° ë‹¨ê³„ì ìœ¼ë¡œ ê°œì„ 
   - ì„±ê³µ ì‚¬ë¡€ ë²¤ì¹˜ë§ˆí‚¹ì„ í†µí•œ ë¹ ë¥¸ ê°œì„ 

3. **í†µí•© ìµœì í™” ì „ëµ**
   - ê°•ì ê³¼ ì•½ì ì˜ ì‹œë„ˆì§€ íš¨ê³¼ ì°½ì¶œ
   - ê³ ê° ê²½í—˜ ì „ë°˜ì˜ í’ˆì§ˆ í–¥ìƒ

### ğŸ’¡ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ í”Œëœ

1. **1ì£¼ì°¨: ê¸´ê¸‰ ê°œì„ **
   - ê°€ì¥ ì•½í•œ ì§€í‘œ 1ê°œì— ì§‘ì¤‘í•œ ì¦‰ì‹œ ê°œì„  ì¡°ì¹˜

2. **2-4ì£¼ì°¨: ë‹¨ê³„ì  ê°œì„ **
   - ë‚˜ë¨¸ì§€ ì•½ì ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ê°œì„ 
   - ê°•ì ì„ ë”ìš± ê°•í™”í•˜ëŠ” ì „ëµ ì‹¤í–‰

3. **1-3ê°œì›”: ì§€ì†ì  ìµœì í™”**
   - ì„±ê³¼ ì¸¡ì • ë° ì „ëµ ì¡°ì •
   - ì¥ê¸°ì ì¸ ê²½ìŸë ¥ í™•ë³´

"""
        return final_report

    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return f"""ğŸš¨ ì „ë°©ìœ„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ìƒì„¸ ì •ë³´:**
- ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}
- ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}
- ê°€ë§¹ì  ID: {store_id}

**í•´ê²° ë°©ë²•:**
1. ê°€ë§¹ì  IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
2. ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ê°€ë§¹ì  ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
3. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”

**ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:**
{error_details}"""
# =============================================================================
# íŠ¹í™” ì§ˆë¬¸ ë„êµ¬ë“¤
# =============================================================================

@tool
def floating_population_strategy_tool(store_id: str, df_all_join: pd.DataFrame, df_gender_age: pd.DataFrame, df_weekday_weekend: pd.DataFrame, df_dayofweek: pd.DataFrame, df_timeband: pd.DataFrame) -> str:
    """
    ì§€í•˜ì² ì—­ ì¸ê·¼ ê°€ë§¹ì ì˜ ìœ ë™ì¸êµ¬ ë°ì´í„°ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬, ì‹ ê·œ ë°©ë¬¸ê°ì„ ë‹¨ê³¨ë¡œ ì „í™˜í•˜ê¸° ìœ„í•œ 'ì¬ë°©ë¬¸ ìœ ë„ ì „ëµ'ì„ ì „ë¬¸ì ìœ¼ë¡œ ì œì•ˆí•˜ëŠ” ë„êµ¬.
    'ìœ ë™ì¸êµ¬', 'ì§€í•˜ì² ì—­', 'ì¶œí‡´ê·¼', 'ì¬ë°©ë¬¸ ìœ ë„' ê´€ë ¨ ì§ˆë¬¸ì— ì‚¬ìš©ëœë‹¤.
    
    Args:
        store_id: ë¶„ì„í•  ê°€ë§¹ì  ID
        df_all_join: ì „ì²´ JOIN ë°ì´í„°
        df_gender_age: ì„±ë³„ì—°ë ¹ëŒ€ë³„ ìœ ë™ì¸êµ¬ ë°ì´í„°
        df_weekday_weekend: ìš”ì¼ë³„ ìœ ë™ì¸êµ¬ ë°ì´í„°
        df_dayofweek: ìš”ì¼ë³„ ìœ ë™ì¸êµ¬ ë°ì´í„°
        df_timeband: ì‹œê°„ëŒ€ë³„ ìœ ë™ì¸êµ¬ ë°ì´í„°
    
    Returns:
        LLMì—ê²Œ ì „ë‹¬í•  ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    """
    try:
        # ë°ì´í„° ì •ê·œí™” ìœ í‹¸ í•¨ìˆ˜ë“¤
        def fmt(x, digits=1):
            try:
                return f"{float(x):,.{digits}f}"
            except Exception:
                return str(x)

        def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
            df = df.copy()
            def norm(s):
                return str(s).replace("\u3000", "").replace(" ", "").strip()
            df.columns = [norm(c) for c in df.columns]
            rename_map = {}
            for c in df.columns:
                if c in ["ì§€í‘œ","í•­ëª©","ë¶„ë¥˜","êµ¬ë¶„ê°’","êµ¬ë¶„*","êµ¬ë¶„_", "êµ¬ë¶„"]:
                    rename_map[c] = "êµ¬ë¶„"
            if rename_map:
                df = df.rename(columns=rename_map)
            return df

        def pick_population_row(df: pd.DataFrame) -> pd.Series:
            df = normalize_columns(df)
            if "êµ¬ë¶„" in df.columns:
                cand = df[df["êµ¬ë¶„"].astype(str).str.contains("ì¸êµ¬")]
                if len(cand):
                    return cand.iloc[0]
            return df.iloc[0]

        # DATA_BLOCK ìƒì„± í•¨ìˆ˜
        def make_data_block(monthly, gender_age, weekday_weekend, dayofweek, timeband, shop_row) -> str:
            lines = []
            shop = shop_row.iloc[0].to_dict() if len(shop_row) else {}
            shop_name = shop.get("MCT_NM", "ê°€ê²Œëª… ë¯¸ìƒ")
            shop_addr = shop.get("MCT_BSE_AR", "ì£¼ì†Œ ë¯¸ìƒ")
            shop_station = shop.get("HPSN_MCT_ZCD_NM", "ì§€í•˜ì² ì—­ ë¯¸ìƒ")
            shop_cat = shop.get("ì—…ì¢…_ì •ê·œí™”1", shop.get("ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜", "ì—…ì¢… ë¯¸ìƒ"))
            shop_month = shop.get("TA_YM", "NA")

            lines.append(f"## SHOP\n[ê°€ê²Œ] {shop_name} | ì—…ì¢…: {shop_cat}\n[ì£¼ì†Œ] {shop_addr}\n[ì¸ê·¼ ì§€í•˜ì² ì—­] {shop_station}\n[ê¸°ì¤€ì›”] {shop_month}")

            # ì„±/ì—°ë ¹
            gender_age = normalize_columns(gender_age)
            ga_row = gender_age.iloc[0]
            ga_total = ga_row.get("ì¼ì¼")
            ga_male = ga_row.get("ë‚¨ì„±")
            ga_female = ga_row.get("ì—¬ì„±")
            ga_lines = []
            if ga_total is not None:
                ga_lines.append(f"ì¼ í‰ê·  ìœ ë™ì¸êµ¬ {fmt(ga_total,0)}ëª…")
            if ga_male is not None and ga_female is not None:
                ga_lines.append(f"ë‚¨ {fmt(ga_male,0)}ëª… / ì—¬ {fmt(ga_female,0)}ëª…")
            lines.append("\n## GENDER_AGE\n" + (" / ".join(ga_lines) if ga_lines else "ì •ë³´ ì—†ìŒ"))

            # ìš”ì¼
            dayofweek = normalize_columns(dayofweek)
            try:
                row = pick_population_row(dayofweek)
                dow_cols = [c for c in row.index if any(x in c for x in ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"])]
                s = row[dow_cols].astype(float).sort_values(ascending=False)[:2]
                lines.append("\n## DAYOFWEEK\nìƒìœ„ ìš”ì¼ TOP2 â†’ " + " / ".join([f"{k}: {fmt(v,0)}ëª…" for k,v in s.items()]))
            except Exception:
                lines.append("\n## DAYOFWEEK\nì •ë³´ ì—†ìŒ")

            # í‰ì¼/ì£¼ë§
            weekday_weekend = normalize_columns(weekday_weekend)
            try:
                row = pick_population_row(weekday_weekend)
                wk_key = "ì£¼ì¤‘" if "ì£¼ì¤‘" in weekday_weekend.columns else ("í‰ì¼" if "í‰ì¼" in weekday_weekend.columns else None)
                we_key = "ì£¼ë§" if "ì£¼ë§" in weekday_weekend.columns else None
                if wk_key and we_key:
                    lines.append(f"\n## WEEKDAY_WEEKEND\ní‰ì¼: {fmt(row[wk_key],0)}ëª…/ì¼ / ì£¼ë§: {fmt(row[we_key],0)}ëª…/ì¼")
                else:
                    lines.append("\n## WEEKDAY_WEEKEND\nì •ë³´ ì—†ìŒ")
            except Exception:
                lines.append("\n## WEEKDAY_WEEKEND\nì •ë³´ ì—†ìŒ")

            # ì‹œê°„ëŒ€
            timeband = normalize_columns(timeband)
            try:
                row = pick_population_row(timeband)
                tb_cols = [c for c in row.index if ("ì‹œ" in c or "~" in c)]
                s = row[tb_cols].astype(float).sort_values(ascending=False)[:3]
                lines.append("\n## TIMEBAND\nì‹œê°„ëŒ€ TOP3 â†’ " + " / ".join([f"{k}: {fmt(v,0)}ëª…" for k,v in s.items()]))
            except Exception:
                lines.append("\n## TIMEBAND\nì •ë³´ ì—†ìŒ")

            return "\n".join(lines)

        # ê°€ë§¹ì  ì •ë³´ ì¡°íšŒ
        shop_row = df_all_join[df_all_join["ENCODED_MCT"] == store_id]
        if shop_row.empty:
            return f"ğŸš¨ ë¶„ì„ ë¶ˆê°€: '{store_id}' ê°€ë§¹ì ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        SYSTEM_PROMPT = """
ë„ˆëŠ” ë™ë„¤ ìƒê¶Œ ë§ˆì¼€íŒ… ì „ëµê°€ë‹¤.
ë‹µë³€ì€ ë‹¤ìŒ ìš°ì„ ìˆœìœ„ë¥¼ ë°˜ë“œì‹œ ì§€ì¼œë¼:
1) ìš°ë¦¬ ê°€ê²ŒëŠ” ì§€í•˜ì² ì—­(ì¶œí‡´ê·¼ ì¸êµ¬ ì¤‘ì‹¬) ê·¼ì²˜ì„ì„ ì „ì œë¡œ, ì‹œê°„ëŒ€ë³„(íŠ¹íˆ ì¶œí‡´ê·¼) ìœ ë™ì¸êµ¬ íŠ¹ì§•ì„ ê°€ì¥ ë¨¼ì € ìš”ì•½
2) ìœ ë™ì¸êµ¬ ì˜ì¡´ë„ê°€ ë†’ì•„ ì‹ ê·œ ë°©ë¬¸ì€ ë§ì§€ë§Œ ì¬ë°©ë¬¸ìœ¨ì´ ë‚®ë‹¤ëŠ” ê°€ì • í•˜ì—, ì¬ë°©ë¬¸ ê³ ê° ìœ ë„ ì „ëµì„ ì¤‘ì‹¬ìœ¼ë¡œ ì œì‹œ
""".strip()

        QUESTION = (
            "ìš°ë¦¬ ê°€ê²ŒëŠ” ì§€í•˜ì² ì—­ ê·¼ì²˜ì— ìˆë‹¤.\n"
            "ë‹µë³€ì€ ì²«ë²ˆì§¸ë¡œ ìš°ë¦¬ ê°€ê²Œ ì£¼ë³€ ìœ ë™ì¸êµ¬ íŠ¹ì„±ì„ ì •ë¦¬í•˜ê³ , íŠ¹íˆ ì§€í•˜ì² ì—­ íŠ¹ì„±ìƒ ì¶œí‡´ê·¼ ì‹œê°„ëŒ€ì˜ ìœ ë™ì¸êµ¬ ë³€í™”ë¥¼ ë¨¼ì € ì„¤ëª…í•´ì¤˜.\n"
            "ê·¸ ë‹¤ìŒ, ìœ ë™ì¸êµ¬ ì˜ì¡´ë„ê°€ ë†’ì•„ì„œ ì‹ ê·œ ë°©ë¬¸ì€ ë§ì§€ë§Œ ì¬ë°©ë¬¸ìœ¨ì´ ë‚®ì€ í¸ì´ë‹¤.\n"
            "ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ì¬ë°©ë¬¸ ê³ ê° ìœ ë„ ì „ëµë§Œ ì§‘ì¤‘í•´ì„œ ì œì‹œí•´ì¤˜."
        )

        def build_prompt(question: str, data_block: str) -> str:
            return f"SYSTEM:\n{SYSTEM_PROMPT}\n\n[ì§ˆë¬¸]\n{question}\n\n[DATA_BLOCK]\n{data_block}"

        # ë°ì´í„° ë¸”ë¡ ìƒì„±
        monthly = pd.DataFrame()  # ì‚¬ìš© ì•ˆí•¨
        data_block = make_data_block(monthly, df_gender_age, df_weekday_weekend, df_dayofweek, df_timeband, shop_row)
        prompt = build_prompt(QUESTION, data_block)
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (API í˜¸ì¶œ ì œê±°)
        return prompt

    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return f"""ğŸš¨ ìœ ë™ì¸êµ¬ ì „ëµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ìƒì„¸ ì •ë³´:**
- ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}
- ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}
- ê°€ë§¹ì  ID: {store_id}

**í•´ê²° ë°©ë²•:**
1. ê°€ë§¹ì  IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
2. ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ê°€ë§¹ì  ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
3. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”

**ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:**
{error_details}"""


@tool
def lunch_turnover_strategy_tool(store_id: str, df_all_join: pd.DataFrame, df_gender_age: pd.DataFrame, df_weekday_weekend: pd.DataFrame, df_dayofweek: pd.DataFrame, df_timeband: pd.DataFrame) -> str:
    """
    ì§ì¥ì¸ ìƒê¶Œì— ìœ„ì¹˜í•œ ê°€ë§¹ì ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ì ì‹¬ í”¼í¬íƒ€ì„ì˜ 'íšŒì „ìœ¨'ì„ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ìš´ì˜ ì „ëµì„ ì œì•ˆí•˜ëŠ” ë„êµ¬.
    'ì§ì¥ì¸', 'ì ì‹¬ì‹œê°„', 'íšŒì „ìœ¨', 'íš¨ìœ¨' ê´€ë ¨ ì§ˆë¬¸ì— ì‚¬ìš©ëœë‹¤.
    
    Args:
        store_id: ë¶„ì„í•  ê°€ë§¹ì  ID
        df_all_join: ì „ì²´ JOIN ë°ì´í„°
        df_gender_age: ì„±ë³„ì—°ë ¹ëŒ€ë³„ ìœ ë™ì¸êµ¬ ë°ì´í„°
        df_weekday_weekend: ìš”ì¼ë³„ ìœ ë™ì¸êµ¬ ë°ì´í„°
        df_dayofweek: ìš”ì¼ë³„ ìœ ë™ì¸êµ¬ ë°ì´í„°
        df_timeband: ì‹œê°„ëŒ€ë³„ ìœ ë™ì¸êµ¬ ë°ì´í„°
    
    Returns:
        LLMì—ê²Œ ì „ë‹¬í•  ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    """
    try:
        # ë°ì´í„° ë„ìš°ë¯¸ í•¨ìˆ˜
        def fmt(x, digits=1):
            try:
                return f"{float(x):,.{digits}f}"
            except Exception:
                return str(x)

        # DATA_BLOCK ìƒì„± í•¨ìˆ˜
        def make_data_block(monthly, gender_age, weekday_weekend, dayofweek, timeband, shop_row) -> str:
            lines = []
            shop = shop_row.iloc[0].to_dict() if len(shop_row) else {}
            shop_name = shop.get("MCT_NM", "ê°€ê²Œëª… ë¯¸ìƒ")
            shop_addr = shop.get("MCT_BSE_AR", "ì£¼ì†Œ ë¯¸ìƒ")
            shop_station = shop.get("HPSN_MCT_ZCD_NM", "ì§€í•˜ì² ì—­ ë¯¸ìƒ")
            shop_cat = shop.get("ì—…ì¢…_ì •ê·œí™”1", shop.get("ì—…ì¢…_ì •ê·œí™”2_ëŒ€ë¶„ë¥˜", "ì—…ì¢… ë¯¸ìƒ"))
            shop_month = shop.get("TA_YM", "NA")

            meta = [
                f"[ê°€ê²Œ] {shop_name} | ì—…ì¢…: {shop_cat}",
                f"[ì£¼ì†Œ] {shop_addr}",
                f"[ì¸ê·¼ ì§€í•˜ì² ì—­] {shop_station}",
                f"[ê¸°ì¤€ì›”] {shop_month}",
            ]
            lines.append("## SHOP\n" + "\n".join(meta))

            # ì„±/ì—°ë ¹
            ga_row = gender_age.iloc[0]
            ga_total = ga_row.get("ì¼ì¼")
            ga_male = ga_row.get("ë‚¨ì„±")
            ga_female = ga_row.get("ì—¬ì„±")
            ga_lines = []
            if ga_total is not None:
                ga_lines.append(f"ì¼ í‰ê·  ìœ ë™ì¸êµ¬ {fmt(ga_total,0)}ëª…")
            if ga_male is not None and ga_female is not None:
                ga_lines.append(f"ë‚¨ {fmt(ga_male,0)}ëª… / ì—¬ {fmt(ga_female,0)}ëª…")
            lines.append("\n## GENDER_AGE\n" + (" / ".join(ga_lines) if ga_lines else "ì •ë³´ ì—†ìŒ"))

            # ìš”ì¼
            if "ì›”" in dayofweek.columns:
                pop_row = dayofweek[dayofweek["êµ¬ë¶„"] == "ì¸êµ¬"].iloc[0]
                top2 = pop_row[["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]].sort_values(ascending=False)[:2]
                top_lines = [f"{idx}: {fmt(val,0)}ëª…" for idx, val in top2.items()]
                lines.append("\n## DAYOFWEEK\nìƒìœ„ ìš”ì¼ TOP2 â†’ " + " / ".join(top_lines))
            else:
                lines.append("\n## DAYOFWEEK\nì •ë³´ ì—†ìŒ")

            # í‰/ì£¼ë§
            if "ì£¼ì¤‘" in weekday_weekend.columns:
                row = weekday_weekend[weekday_weekend["êµ¬ë¶„"] == "ì¸êµ¬"].iloc[0]
                wk = f"í‰ì¼: {fmt(row['ì£¼ì¤‘'], 0)}ëª…/ì¼"
                we = f"ì£¼ë§: {fmt(row['ì£¼ë§'], 0)}ëª…/ì¼"
                lines.append("\n## WEEKDAY_WEEKEND\n" + wk + " / " + we)
            else:
                lines.append("\n## WEEKDAY_WEEKEND\nì •ë³´ ì—†ìŒ")

            # ì‹œê°„ëŒ€
            row = timeband[timeband["êµ¬ë¶„"] == "ì¸êµ¬"].iloc[0]
            top3 = row[["05~09ì‹œ", "09~12ì‹œ", "12~14ì‹œ", "14~18ì‹œ", "18~23ì‹œ", "23~05ì‹œ"]].sort_values(ascending=False)[:3]
            time_lines = [f"{idx}: {fmt(val,0)}ëª…" for idx, val in top3.items()]
            lines.append("\n## TIMEBAND\nì‹œê°„ëŒ€ TOP3 â†’ " + " / ".join(time_lines))

            return "\n".join(lines)

        # ê°€ë§¹ì  ì •ë³´ ì¡°íšŒ
        shop_row = df_all_join[df_all_join["ENCODED_MCT"] == store_id]
        if shop_row.empty:
            return f"ğŸš¨ ë¶„ì„ ë¶ˆê°€: '{store_id}' ê°€ë§¹ì ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        SYSTEM_PROMPT = """
ë„ˆëŠ” ë™ë„¤ ìƒê¶Œ ë§ˆì¼€íŒ… ì „ëµê°€ë‹¤.
ë°˜ë“œì‹œ ì œê³µëœ DATA_BLOCKë§Œ ê·¼ê±°ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµì„ ì œì‹œí•œë‹¤.
ë‹µë³€ì€ ë‹¤ìŒ ìš°ì„ ìˆœìœ„ë¥¼ ë°˜ë“œì‹œ ì§€ì¼œë¼:
1) ê·¼ì²˜ ì§ì¥ì¸êµ¬ì— ëŒ€í•œ ë¶„ì„, ì£¼ë§ê³¼ í‰ì¼ ì§ì¥ì¸êµ¬ ë¹„êµ ë“± ì—¬ëŸ¬ ë¶„ì„ í›„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜
2) ì§ì¥ì¸ ë°©ë¬¸ ë¹„ìœ¨ì´ ë†’ì€ ì—…ì¢… íŠ¹ì„±ìƒ íšŒì „ë¥ ì´ í•µì‹¬ KPIì„ì„ ë°˜ì˜í•˜ì—¬, ì ì‹¬ì‹œê°„ íšŒì „ìœ¨ì„ ë†’ì´ê¸° ìœ„í•œ ì „ëµì„ ì œì‹œí•  ê²ƒ
""".strip()

        QUESTION = (
            "ìš°ë¦¬ ê°€ê²ŒëŠ” ì§ì¥ì¸ ê³ ê°ì´ ì£¼ìš” íƒ€ê²Ÿì´ë©°, ì ì‹¬ì‹œê°„ì— í•´ë‹¹í•˜ëŠ” ìœ ë™ì¸êµ¬ì™€ ì§ì¥ì¸êµ¬ì˜ ë¶„ì„ì„ ìƒì„¸íˆ ì„¤ëª…í•´ì¤˜.\n"
            "1) ì ì‹¬ì‹œê°„ ì§ì¥ì¸êµ¬ íŠ¹ì„±ì„ ìš”ì•½í•´ì¤˜\n"
            "2) ì ì‹¬ í”¼í¬íƒ€ì„ì— íšŒì „ìœ¨ì„ ë†’ì´ê¸° ìœ„í•œ ì „ëµì„ ì œì‹œí•´ì¤˜"
        )

        def build_prompt(question: str, data_block: str) -> str:
            return f"SYSTEM:\n{SYSTEM_PROMPT}\n\n[ì§ˆë¬¸]\n{question}\n\n[DATA_BLOCK]\n{data_block}"

        # ë°ì´í„° ë¸”ë¡ ìƒì„±
        monthly = pd.DataFrame()  # ì‚¬ìš© ì•ˆí•¨
        data_block = make_data_block(monthly, df_gender_age, df_weekday_weekend, df_dayofweek, df_timeband, shop_row)
        prompt = build_prompt(QUESTION, data_block)
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (API í˜¸ì¶œ ì œê±°)
        return prompt

    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return f"""ğŸš¨ ì ì‹¬ì‹œê°„ íšŒì „ìœ¨ ì „ëµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ì˜¤ë¥˜ ìƒì„¸ ì •ë³´:**
- ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}
- ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}
- ê°€ë§¹ì  ID: {store_id}

**í•´ê²° ë°©ë²•:**
1. ê°€ë§¹ì  IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
2. ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ê°€ë§¹ì  ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
3. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”

**ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:**
{error_details}"""
